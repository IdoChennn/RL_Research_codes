{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbdd224146c7e62",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-16T21:26:16.598062141Z",
     "start_time": "2024-03-16T21:26:16.596969586Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)  # Change from 1 to 3 input channels\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 120)  # Adjust the size for CIFAR-10\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 5 * 5)  # Adjust the size for CIFAR-10\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def create_non_iid_partitions(dataset, num_clients, additional_samples_per_client=100):\n",
    "    num_classes = 10\n",
    "    class_indices = [[] for _ in range(num_classes)]\n",
    "    \n",
    "    for idx, (_, label) in enumerate(dataset):\n",
    "        class_indices[label].append(idx)\n",
    "    \n",
    "    # Ensure randomness in class selection for each client\n",
    "    all_classes = list(range(num_classes))\n",
    "    \n",
    "    client_local_datasets = []\n",
    "    for i in range(num_clients):\n",
    "        # Randomly select two major classes for each client\n",
    "        major_classes = random.sample(all_classes, 2)\n",
    "\n",
    "        # Allocate all data from the two major classes\n",
    "        client_indices = class_indices[major_classes[0]] + class_indices[major_classes[1]]\n",
    "        \n",
    "        #Add a small number of samples from other classes\n",
    "        minor_indices = []\n",
    "        for cls in set(range(num_classes)) - set(major_classes):\n",
    "            n_samples = len(class_indices[cls]) // num_clients // statistical_heterogeneity  # 50 times less than major classes\n",
    "            minor_indices.extend(class_indices[cls][i * n_samples: (i + 1) * n_samples])\n",
    "\n",
    "        client_indices = client_indices + minor_indices\n",
    "        random.shuffle(client_indices)  # Shuffle to mix data from different classes\n",
    "        client_local_datasets.append(data_utils.Subset(dataset, client_indices))\n",
    "\n",
    "    return client_local_datasets\n",
    "\n",
    "def create_iid_partitions(dataset, num_clients):\n",
    "\n",
    "    client_datasets = []\n",
    "    for i in range(num_clients):\n",
    "        client_dataset = data_utils.Subset(dataset, list(range(i * len(dataset) // num_clients, (i + 1) * len(dataset) // num_clients)))\n",
    "        client_datasets.append(client_dataset)\n",
    "    return client_datasets\n",
    "\n",
    "def server_aggregate(state_dict_list):\n",
    "    # average the model\n",
    "    aggregated_state = {}\n",
    "    for key,parameter in model.named_parameters():\n",
    "        tensor_to_aggregate = []\n",
    "        for client_state_dict in state_dict_list:\n",
    "            client_tensor = client_state_dict[key].float()\n",
    "            tensor_to_aggregate.append(client_tensor)\n",
    "        \n",
    "        stacked_tensor = torch.stack(tensor_to_aggregate,dim=0)\n",
    "        mean_tensor = torch.mean(stacked_tensor,dim=0)\n",
    "        aggregated_state[key] = mean_tensor\n",
    "    model.load_state_dict(aggregated_state)\n",
    "\n",
    "    return model \n",
    "\n",
    "def difference_models_norm_2(local_model, initial_model):\n",
    "    tensor_1 = list(local_model.parameters())\n",
    "    tensor_2 = list(initial_model.parameters())\n",
    "    sub_norm = []\n",
    "    for i in range(len(tensor_1)):\n",
    "        s = torch.norm(tensor_1[i].to(myGPU) - tensor_2[i].to(myGPU),p=2)\n",
    "        sub_norm.append(s)\n",
    "    return sum(sub_norm)\n",
    "\n",
    "def client_update(received_model, train_data, local_optimizer, loss_f, epoch,client_id,mu,sigma,loss_difference,last_global_loss,algorithm,sys_heter):\n",
    "\n",
    "    local_model = received_model.to(myGPU)\n",
    "    initial_model = received_model.to(myGPU)\n",
    "    \n",
    "    random_chance = random.randint(0, 10) # Randomly decide if the client is weak or strong\n",
    "    if random_chance > sys_heter or algorithm == \"FedProx\": # In fedprox, all clients train, those weaker clients will train less according to sigma; In FedAvg, only strong clients train\n",
    "        \n",
    "        # if a client is strong in FedAvg, perform full training, if not drop it; in FedProx, all clients train and the amount of training is determined by sigma\n",
    "    \n",
    "        print(f\"Client {client_id+1} starts training...\")\n",
    "        print(f\"losss difference: {loss_difference}\")\n",
    "        print(f\"last global loss: {last_global_loss}\")\n",
    "        model.train()\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(epoch):\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for feature, label in train_data:\n",
    "                local_optimizer.zero_grad()\n",
    "                feature, label = feature.to(myGPU), label.to(myGPU)\n",
    "                outputs = local_model(feature)\n",
    "                local_loss = loss_f(outputs, label)\n",
    "                loss_prox = (mu / 2) * difference_models_norm_2(local_model, initial_model) # perform model updates penalization using proximal term\n",
    "                loss = local_loss + loss_prox\n",
    "                loss.backward()\n",
    "                local_optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            if (abs(running_loss / len(train_data) - last_global_loss) < sigma*abs(loss_difference) or running_loss / len(train_data) < sigma*loss_difference) and algorithm == \"FedProx\": # allow good enough results for all clients\n",
    "                \n",
    "                print(f\"Client {client_id+1} stops training at epoch {i+1} because good enough results hve been obtained at Loss: {running_loss / len(train_data)}\")\n",
    "                break\n",
    "            print(running_loss / len(train_data) < sigma*loss_difference)\n",
    "            print(f\"Epoch {i+1} loss: {running_loss / len(train_data)}\")\n",
    "        print(\"\\n\")\n",
    "        return model.state_dict()\n",
    "    \n",
    "    \n",
    "    else: # If the client is weak, it will not train\n",
    "        print(f\"Client {client_id+1} dropped\")\n",
    "        return model.state_dict()\n",
    "\n",
    "\n",
    "def evaluate(model, testloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for test_feature, test_labels in testloader:\n",
    "         \n",
    "            test_feature, test_labels = test_feature.to(myGPU), test_labels.to(myGPU)\n",
    "            outputs = model(test_feature)\n",
    "            test_loss = loss_function(outputs, test_labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += test_labels.size(0)\n",
    "            correct += (predicted == test_labels).sum().item()\n",
    "            test_loss += test_loss.item()\n",
    "    accuracy = 100 * correct / total\n",
    "    loss = test_loss / len(testloader)\n",
    "\n",
    "    print(f\"Accuracy of the network: {accuracy}, Loss: {loss}\")\n",
    "    return [accuracy, loss]\n",
    "\n",
    "\n",
    "\n",
    "def federated_learning(model, mu, sigma,client_datasets, testloader, optimizer, loss_function, global_epochs, local_epochs,algorithm,sys_heter):\n",
    "    \n",
    "    for i, client_dataset in enumerate(client_datasets):\n",
    "        client_labels = [trainset.targets[idx] for idx in client_dataset.indices]  # Access the labels for each subset\n",
    "        unique_labels = np.unique(client_labels)\n",
    "        print(f\"Client {i} has {len(unique_labels)} unique labels: {unique_labels}, and {len(client_dataset)} samples\")\n",
    "        \n",
    "    initial_phase = evaluate(model, testloader)\n",
    "    loss_difference = 0\n",
    "    global_loss = initial_phase[1]\n",
    "    print(f\"Initial loss: {global_loss} Accuracy: {initial_phase[0]}\")        \n",
    "    print(\"Training Starting .......\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Create a dataloader for each client\n",
    "    client_dataloaders = [data_utils.DataLoader(dataset, batch_size=256, shuffle=True, num_workers=2) for dataset in client_datasets]\n",
    "    global_history = []\n",
    "    for global_epoch in range(global_epochs):\n",
    "        \n",
    "        print(f\" ====================== Global Round {global_epoch+1} ======================\")\n",
    "        state_dicts = []\n",
    "        for client_id, client_dataloader in enumerate(client_dataloaders):\n",
    "            \n",
    "            client_state_dict = client_update(model, client_dataloader, optimizer, loss_function, local_epochs,client_id,mu,sigma,loss_difference,global_loss,algorithm,sys_heter)\n",
    "            state_dicts.append(client_state_dict)\n",
    "        \n",
    "        global_model = server_aggregate(state_dicts)\n",
    "        model.load_state_dict(global_model.state_dict())\n",
    "        \n",
    "        \n",
    "        # This one is to find the deviation between current global model and the previous global model. Note that our sigma will adjust this deviation to determine the amount of training for each client\n",
    "        one_global_hist = evaluate(model, testloader)\n",
    "        loss_difference = one_global_hist[1] - global_loss\n",
    "        global_loss = one_global_hist[1]\n",
    "        print(f\"Loss difference: {loss_difference}\")\n",
    "        print(f\"Global Round {global_epoch+1} ends\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        global_history.append(one_global_hist)\n",
    "        \n",
    "    return global_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training set up using CIFAR-10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d01701916cf97947"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "myGPU = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(myGPU)\n",
    "# load the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "global_epochs = 20\n",
    "local_epochs = 30\n",
    "number_of_clients = 5\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T21:26:16.642895832Z",
     "start_time": "2024-03-16T21:26:16.599327091Z"
    }
   },
   "id": "cb9f18100337567d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training without System and Statistical Homogeneity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36a095ea4376a75e"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 has 10 unique labels: [0 1 2 3 4 5 6 7 8 9], and 12000 samples\n",
      "Client 1 has 10 unique labels: [0 1 2 3 4 5 6 7 8 9], and 12000 samples\n",
      "Client 2 has 10 unique labels: [0 1 2 3 4 5 6 7 8 9], and 12000 samples\n",
      "Client 3 has 10 unique labels: [0 1 2 3 4 5 6 7 8 9], and 12000 samples\n",
      "Client 4 has 10 unique labels: [0 1 2 3 4 5 6 7 8 9], and 12000 samples\n",
      "Accuracy of the network: 11.35, Loss: 0.029324064031243324\n",
      "Initial loss: 0.029324064031243324 Accuracy: 11.35\n",
      "Training Starting .......\n",
      "\n",
      "\n",
      " ====================== Global Round 1 ======================\n",
      "Client 1 starts training...\n",
      "losss difference: 0\n",
      "last global loss: 0.029324064031243324\n",
      "Epoch 1 loss: 1.3279914817911513\n",
      "Epoch 2 loss: 0.21597283270130765\n",
      "Epoch 3 loss: 0.1299020571267589\n",
      "Epoch 4 loss: 0.08986875721738931\n",
      "Epoch 5 loss: 0.0760790641280882\n",
      "Epoch 6 loss: 0.0590995452787846\n",
      "Epoch 7 loss: 0.05034363210174017\n",
      "Epoch 8 loss: 0.03901883460794318\n",
      "Epoch 9 loss: 0.03459396578608071\n",
      "Epoch 10 loss: 0.02626468239480907\n",
      "Epoch 11 loss: 0.024334979894232906\n",
      "Epoch 12 loss: 0.019506361437998613\n",
      "Epoch 13 loss: 0.012993994776402264\n",
      "Epoch 14 loss: 0.01040986281038792\n",
      "Epoch 15 loss: 0.007129372810653721\n",
      "Epoch 16 loss: 0.006735384136845823\n",
      "Epoch 17 loss: 0.004266431450501996\n",
      "Epoch 18 loss: 0.002703640515934007\n",
      "Epoch 19 loss: 0.001239562805068922\n",
      "Epoch 20 loss: 0.0007061015997888194\n",
      "Epoch 21 loss: 0.0005793148356268772\n",
      "Epoch 22 loss: 0.0005160825717889276\n",
      "Epoch 23 loss: 0.0004295960477520566\n",
      "Epoch 24 loss: 0.0003625719275581279\n",
      "Epoch 25 loss: 0.00033546628721640135\n",
      "Epoch 26 loss: 0.0003124863609485224\n",
      "Epoch 27 loss: 0.00028011935692580044\n",
      "Epoch 28 loss: 0.0002608601392716024\n",
      "Epoch 29 loss: 0.00024425524259186204\n",
      "Epoch 30 loss: 0.00022405574500008367\n",
      "\n",
      "\n",
      "Client 2 starts training...\n",
      "losss difference: 0\n",
      "last global loss: 0.029324064031243324\n",
      "Epoch 1 loss: 0.10122961015897206\n",
      "Epoch 2 loss: 0.046080222566509274\n",
      "Epoch 3 loss: 0.034237500002726594\n",
      "Epoch 4 loss: 0.02005277983002127\n",
      "Epoch 5 loss: 0.012712276672128282\n",
      "Epoch 6 loss: 0.014225741979162\n",
      "Epoch 7 loss: 0.010328204850938686\n",
      "Epoch 8 loss: 0.009336408508038694\n",
      "Epoch 9 loss: 0.0033771598510669563\n",
      "Epoch 10 loss: 0.0016483200263869644\n",
      "Epoch 11 loss: 0.0009640133695764699\n",
      "Epoch 12 loss: 0.0006384558866286286\n",
      "Epoch 13 loss: 0.00045948763586190405\n",
      "Epoch 14 loss: 0.00038562105809423304\n",
      "Epoch 15 loss: 0.00034150498019234294\n",
      "Epoch 16 loss: 0.0003039827502494092\n",
      "Epoch 17 loss: 0.0002740234983092405\n",
      "Epoch 18 loss: 0.000255162708508022\n",
      "Epoch 19 loss: 0.00022987372956273982\n",
      "Epoch 20 loss: 0.0002178360399233633\n",
      "Epoch 21 loss: 0.00020075584117399615\n",
      "Epoch 22 loss: 0.00018708657476695215\n",
      "Epoch 23 loss: 0.0001749515578179408\n",
      "Epoch 24 loss: 0.0001651194936769382\n",
      "Epoch 25 loss: 0.0001591021611138205\n",
      "Epoch 26 loss: 0.0001484430390567642\n",
      "Epoch 27 loss: 0.00014270191547016933\n",
      "Epoch 28 loss: 0.00013480214841031719\n",
      "Epoch 29 loss: 0.0001289183269376097\n",
      "Epoch 30 loss: 0.0001231748557090475\n",
      "\n",
      "\n",
      "Client 3 starts training...\n",
      "losss difference: 0\n",
      "last global loss: 0.029324064031243324\n",
      "Epoch 1 loss: 0.08767049948863209\n",
      "Epoch 2 loss: 0.03685320083651335\n",
      "Epoch 3 loss: 0.024312241412460817\n",
      "Epoch 4 loss: 0.01627596016949107\n",
      "Epoch 5 loss: 0.010301945256094071\n",
      "Epoch 6 loss: 0.005844577992997693\n",
      "Epoch 7 loss: 0.005846902650947858\n",
      "Epoch 8 loss: 0.00285412795434008\n",
      "Epoch 9 loss: 0.0022433468696633893\n",
      "Epoch 10 loss: 0.001567626182040453\n",
      "Epoch 11 loss: 0.0010294372034664737\n",
      "Epoch 12 loss: 0.0007032322700689156\n",
      "Epoch 13 loss: 0.0005799866523818039\n",
      "Epoch 14 loss: 0.0004902578206035306\n",
      "Epoch 15 loss: 0.000448369600714246\n",
      "Epoch 16 loss: 0.00040102049751780254\n",
      "Epoch 17 loss: 0.00036041246966441517\n",
      "Epoch 18 loss: 0.00033218495701824375\n",
      "Epoch 19 loss: 0.00030467847675529986\n",
      "Epoch 20 loss: 0.00027886411891978106\n",
      "Epoch 21 loss: 0.0002545989786704787\n",
      "Epoch 22 loss: 0.00023966372098831268\n",
      "Epoch 23 loss: 0.00022666920342737982\n",
      "Epoch 24 loss: 0.00021088157296905128\n",
      "Epoch 25 loss: 0.00019936433820592046\n",
      "Epoch 26 loss: 0.00018957944972653614\n",
      "Epoch 27 loss: 0.00018100775932475337\n",
      "Epoch 28 loss: 0.00017166124859554512\n",
      "Epoch 29 loss: 0.00016443502005600711\n",
      "Epoch 30 loss: 0.00015659988583167355\n",
      "\n",
      "\n",
      "Client 4 starts training...\n",
      "losss difference: 0\n",
      "last global loss: 0.029324064031243324\n",
      "Epoch 1 loss: 0.09293021196610929\n",
      "Epoch 2 loss: 0.038390782903855114\n",
      "Epoch 3 loss: 0.024872738205111943\n",
      "Epoch 4 loss: 0.018779600565779975\n",
      "Epoch 5 loss: 0.011935733047373125\n",
      "Epoch 6 loss: 0.007737980609276069\n",
      "Epoch 7 loss: 0.0047360447367785306\n",
      "Epoch 8 loss: 0.0038043198991293504\n",
      "Epoch 9 loss: 0.0027411639579092498\n",
      "Epoch 10 loss: 0.0017445005095435184\n",
      "Epoch 11 loss: 0.001273972827211184\n",
      "Epoch 12 loss: 0.0007853208728986229\n",
      "Epoch 13 loss: 0.0007295417999775383\n",
      "Epoch 14 loss: 0.0005922360384316717\n",
      "Epoch 15 loss: 0.0005095140502447143\n",
      "Epoch 16 loss: 0.0004179747899224531\n",
      "Epoch 17 loss: 0.00037309461208497426\n",
      "Epoch 18 loss: 0.00032468242020428914\n",
      "Epoch 19 loss: 0.0003051213846573135\n",
      "Epoch 20 loss: 0.0002838650067245608\n",
      "Epoch 21 loss: 0.0002513444532041831\n",
      "Epoch 22 loss: 0.00022454657558692486\n",
      "Epoch 23 loss: 0.00022834243576141944\n",
      "Epoch 24 loss: 0.00021515154376664726\n",
      "Epoch 25 loss: 0.0001866275065004687\n",
      "Epoch 26 loss: 0.00018790862728511296\n",
      "Epoch 27 loss: 0.00017601853085729902\n",
      "Epoch 28 loss: 0.00016674725039360675\n",
      "Epoch 29 loss: 0.00015390778793017304\n",
      "Epoch 30 loss: 0.0001499071731874655\n",
      "\n",
      "\n",
      "Client 5 starts training...\n",
      "losss difference: 0\n",
      "last global loss: 0.029324064031243324\n",
      "Epoch 1 loss: 0.07982009918262695\n",
      "Epoch 2 loss: 0.03284848918872043\n",
      "Epoch 3 loss: 0.017035524340555757\n",
      "Epoch 4 loss: 0.010488934777156905\n",
      "Epoch 5 loss: 0.006798691869180209\n",
      "Epoch 6 loss: 0.004044727747586489\n",
      "Epoch 7 loss: 0.002992023981355584\n",
      "Epoch 8 loss: 0.0021410993527713295\n",
      "Epoch 9 loss: 0.0013707749131328377\n",
      "Epoch 10 loss: 0.0010163870661307692\n",
      "Epoch 11 loss: 0.0007685155006980649\n",
      "Epoch 12 loss: 0.0006229659537618144\n",
      "Epoch 13 loss: 0.0004788803572492202\n",
      "Epoch 14 loss: 0.00041737045489027993\n",
      "Epoch 15 loss: 0.0003650826761234752\n",
      "Epoch 16 loss: 0.00031595179553791085\n",
      "Epoch 17 loss: 0.000278993535889253\n",
      "Epoch 18 loss: 0.0002518245850190377\n",
      "Epoch 19 loss: 0.00024084925989809755\n",
      "Epoch 20 loss: 0.00022064079369682346\n",
      "Epoch 21 loss: 0.00019965728740602417\n",
      "Epoch 22 loss: 0.00018912796717317895\n",
      "Epoch 23 loss: 0.0001749379411105952\n",
      "Epoch 24 loss: 0.00016649770498496707\n",
      "Epoch 25 loss: 0.00015401632632308472\n",
      "Epoch 26 loss: 0.000146137206785884\n",
      "Epoch 27 loss: 0.00013955647813190808\n",
      "Epoch 28 loss: 0.00013179404632584455\n",
      "Epoch 29 loss: 0.00012673709403059625\n",
      "Epoch 30 loss: 0.00011842267589928908\n",
      "\n",
      "Accuracy of the network: 98.83, Loss: 1.898236984265722e-10\n",
      "Loss difference: -0.029324064031243324\n",
      "Global Round 0 ends\n",
      "\n",
      "\n",
      " ====================== Global Round 2 ======================\n",
      "Client 1 starts training...\n",
      "losss difference: -0.029324064031243324\n",
      "last global loss: 1.898236984265722e-10\n",
      "Epoch 1 loss: 0.05907093501391888\n",
      "Epoch 2 loss: 0.01993040090267041\n",
      "Epoch 3 loss: 0.007182689414732638\n",
      "Epoch 4 loss: 0.004318859645033452\n",
      "Epoch 5 loss: 0.0019227000031746006\n",
      "Epoch 6 loss: 0.000767617784810169\n",
      "Epoch 7 loss: 0.0004954282995215104\n",
      "Epoch 8 loss: 0.0002852625799892423\n",
      "Epoch 9 loss: 0.00023965508439517934\n",
      "Epoch 10 loss: 0.00020397692044249932\n",
      "Epoch 11 loss: 0.00017888705758650758\n",
      "Epoch 12 loss: 0.00015871725941662027\n",
      "Epoch 13 loss: 0.0001464766253145336\n",
      "Epoch 14 loss: 0.000133272515223867\n",
      "Epoch 15 loss: 0.00012293328997773332\n",
      "Epoch 16 loss: 0.00011373962443188131\n",
      "Epoch 17 loss: 0.0001056750048813354\n",
      "Epoch 18 loss: 9.93265765479938e-05\n",
      "Epoch 19 loss: 9.354478122519778e-05\n",
      "Epoch 20 loss: 8.811763021631751e-05\n",
      "Epoch 21 loss: 8.312427175065687e-05\n",
      "Epoch 22 loss: 7.919922233457889e-05\n",
      "Epoch 23 loss: 7.510936589059906e-05\n",
      "Epoch 24 loss: 7.16383070591456e-05\n",
      "Epoch 25 loss: 6.875751346209403e-05\n",
      "Epoch 26 loss: 6.627522579003895e-05\n",
      "Epoch 27 loss: 6.308328422938512e-05\n",
      "Epoch 28 loss: 6.090088323524111e-05\n",
      "Epoch 29 loss: 5.841522850468641e-05\n",
      "Epoch 30 loss: 5.623534923204067e-05\n",
      "\n",
      "\n",
      "Client 2 starts training...\n",
      "losss difference: -0.029324064031243324\n",
      "last global loss: 1.898236984265722e-10\n",
      "Epoch 1 loss: 0.05059735690579049\n",
      "Epoch 2 loss: 0.013734771265185276\n",
      "Epoch 3 loss: 0.006885143250075727\n",
      "Epoch 4 loss: 0.002497860129377396\n",
      "Epoch 5 loss: 0.0007604940382857132\n",
      "Epoch 6 loss: 0.0003901200030191284\n",
      "Epoch 7 loss: 0.0002362236298449232\n",
      "Epoch 8 loss: 0.0001927942076845477\n",
      "Epoch 9 loss: 0.0001663963659347188\n",
      "Epoch 10 loss: 0.00014665614432918486\n",
      "Epoch 11 loss: 0.00013197961767941898\n",
      "Epoch 12 loss: 0.00011966227579519193\n",
      "Epoch 13 loss: 0.00011024340293101403\n",
      "Epoch 14 loss: 0.00010163445870450638\n",
      "Epoch 15 loss: 9.510036852226279e-05\n",
      "Epoch 16 loss: 8.891067618888735e-05\n",
      "Epoch 17 loss: 8.364282676307133e-05\n",
      "Epoch 18 loss: 7.975701606589628e-05\n",
      "Epoch 19 loss: 7.476930193387915e-05\n",
      "Epoch 20 loss: 7.130366729980063e-05\n",
      "Epoch 21 loss: 6.748659096807784e-05\n",
      "Epoch 22 loss: 6.465085705149539e-05\n",
      "Epoch 23 loss: 6.185499428416984e-05\n",
      "Epoch 24 loss: 5.9271769703656825e-05\n",
      "Epoch 25 loss: 5.692875303510691e-05\n",
      "Epoch 26 loss: 5.4689386699242564e-05\n",
      "Epoch 27 loss: 5.2859068097370194e-05\n",
      "Epoch 28 loss: 5.0955403235595314e-05\n",
      "Epoch 29 loss: 4.925000722569118e-05\n",
      "Epoch 30 loss: 4.796821681544374e-05\n",
      "\n",
      "\n",
      "Client 3 starts training...\n",
      "losss difference: -0.029324064031243324\n",
      "last global loss: 1.898236984265722e-10\n",
      "Epoch 1 loss: 0.04562824524628303\n",
      "Epoch 2 loss: 0.013408842846129506\n",
      "Epoch 3 loss: 0.003933392991905535\n",
      "Epoch 4 loss: 0.0015354196938837863\n",
      "Epoch 5 loss: 0.0007073732078831025\n",
      "Epoch 6 loss: 0.0004583769121023927\n",
      "Epoch 7 loss: 0.0003655929117872376\n",
      "Epoch 8 loss: 0.0003025258757138835\n",
      "Epoch 9 loss: 0.00026536051588054566\n",
      "Epoch 10 loss: 0.00022972654286975962\n",
      "Epoch 11 loss: 0.00020765609194695764\n",
      "Epoch 12 loss: 0.00018796996576709454\n",
      "Epoch 13 loss: 0.0001696700747427947\n",
      "Epoch 14 loss: 0.0001563269122821692\n",
      "Epoch 15 loss: 0.00014510336601557703\n",
      "Epoch 16 loss: 0.0001354721083645354\n",
      "Epoch 17 loss: 0.00012647366841384366\n",
      "Epoch 18 loss: 0.00011864698062364379\n",
      "Epoch 19 loss: 0.0001113315760221667\n",
      "Epoch 20 loss: 0.00010597160467827575\n",
      "Epoch 21 loss: 0.00010033778100391756\n",
      "Epoch 22 loss: 9.512032563404628e-05\n",
      "Epoch 23 loss: 9.075095608354326e-05\n",
      "Epoch 24 loss: 8.68957644000757e-05\n",
      "Epoch 25 loss: 8.348825136022968e-05\n",
      "Epoch 26 loss: 8.007473160707251e-05\n",
      "Epoch 27 loss: 7.688249618234615e-05\n",
      "Epoch 28 loss: 7.451587398809189e-05\n",
      "Epoch 29 loss: 7.124020479196549e-05\n",
      "Epoch 30 loss: 6.87062367131195e-05\n",
      "\n",
      "\n",
      "Client 4 starts training...\n",
      "losss difference: -0.029324064031243324\n",
      "last global loss: 1.898236984265722e-10\n",
      "Epoch 1 loss: 0.046760992644802636\n",
      "Epoch 2 loss: 0.012737641123439584\n",
      "Epoch 3 loss: 0.0038194249900311175\n",
      "Epoch 4 loss: 0.0021131885585592945\n",
      "Epoch 5 loss: 0.0013797318151580141\n",
      "Epoch 6 loss: 0.0012608572259610578\n",
      "Epoch 7 loss: 0.0004911133629330505\n",
      "Epoch 8 loss: 0.0003929875052766333\n",
      "Epoch 9 loss: 0.0003478663132546957\n",
      "Epoch 10 loss: 0.00029797005330247555\n",
      "Epoch 11 loss: 0.00024959210445244255\n",
      "Epoch 12 loss: 0.000210565284941793\n",
      "Epoch 13 loss: 0.0001893111816964102\n",
      "Epoch 14 loss: 0.00017693491685968958\n",
      "Epoch 15 loss: 0.00015488203679067138\n",
      "Epoch 16 loss: 0.000151243793199678\n",
      "Epoch 17 loss: 0.00013590278598712153\n",
      "Epoch 18 loss: 0.00012837218695073928\n",
      "Epoch 19 loss: 0.00012021568449697836\n",
      "Epoch 20 loss: 0.00011235803701753595\n",
      "Epoch 21 loss: 0.00010783041013438533\n",
      "Epoch 22 loss: 0.00010135276899650259\n",
      "Epoch 23 loss: 9.869064791156776e-05\n",
      "Epoch 24 loss: 9.563454172737383e-05\n",
      "Epoch 25 loss: 8.949770782954659e-05\n",
      "Epoch 26 loss: 8.47965653529753e-05\n",
      "Epoch 27 loss: 8.126633217311236e-05\n",
      "Epoch 28 loss: 7.900503528024641e-05\n",
      "Epoch 29 loss: 7.540661664506842e-05\n",
      "Epoch 30 loss: 7.329024095767825e-05\n",
      "\n",
      "\n",
      "Client 5 dropped\n",
      "Accuracy of the network: 98.95, Loss: 1.898236984265722e-10\n",
      "Loss difference: 0.0\n",
      "Global Round 1 ends\n",
      "\n",
      "\n",
      " ====================== Global Round 3 ======================\n",
      "Client 1 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 1.898236984265722e-10\n",
      "Epoch 1 loss: 0.03157957907077897\n",
      "Epoch 2 loss: 0.00943824626986188\n",
      "Epoch 3 loss: 0.005368993252470821\n",
      "Epoch 4 loss: 0.001201478831406873\n",
      "Epoch 5 loss: 0.00034866937846195564\n",
      "Epoch 6 loss: 0.00020108795250027537\n",
      "Epoch 7 loss: 0.00016204018317601614\n",
      "Epoch 8 loss: 0.00013774705317541217\n",
      "Epoch 9 loss: 0.00012041934705080698\n",
      "Epoch 10 loss: 0.00010841890662352349\n",
      "Epoch 11 loss: 9.713774187503077e-05\n",
      "Epoch 12 loss: 8.895132207501464e-05\n",
      "Epoch 13 loss: 8.201359581860856e-05\n",
      "Epoch 14 loss: 7.616244675320554e-05\n",
      "Epoch 15 loss: 7.084482451770487e-05\n",
      "Epoch 16 loss: 6.659109729140071e-05\n",
      "Epoch 17 loss: 6.253030600349004e-05\n",
      "Epoch 18 loss: 5.917943769245697e-05\n",
      "Epoch 19 loss: 5.6245059072754644e-05\n",
      "Epoch 20 loss: 5.3612772386988455e-05\n",
      "Epoch 21 loss: 5.0749451016571656e-05\n",
      "Epoch 22 loss: 4.849989131610575e-05\n",
      "Epoch 23 loss: 4.626255055299113e-05\n",
      "Epoch 24 loss: 4.4427892430092546e-05\n",
      "Epoch 25 loss: 4.279796629817608e-05\n",
      "Epoch 26 loss: 4.127726101182831e-05\n",
      "Epoch 27 loss: 3.960047054453966e-05\n",
      "Epoch 28 loss: 3.816529993372342e-05\n",
      "Epoch 29 loss: 3.6843038818863366e-05\n",
      "Epoch 30 loss: 3.563965755192646e-05\n",
      "\n",
      "\n",
      "Client 2 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 1.898236984265722e-10\n",
      "Epoch 1 loss: 0.022769453137204843\n",
      "Epoch 2 loss: 0.008929909121433112\n",
      "Epoch 3 loss: 0.00294831029852347\n",
      "Epoch 4 loss: 0.0007758937416805955\n",
      "Epoch 5 loss: 0.00018380200960680358\n",
      "Epoch 6 loss: 0.0001228504788143032\n",
      "Epoch 7 loss: 0.00010321666476414143\n",
      "Epoch 8 loss: 8.997755883277196e-05\n",
      "Epoch 9 loss: 8.08802555157924e-05\n",
      "Epoch 10 loss: 7.322263128704081e-05\n",
      "Epoch 11 loss: 6.698268650393674e-05\n",
      "Epoch 12 loss: 6.220503055111085e-05\n",
      "Epoch 13 loss: 5.737660844588729e-05\n",
      "Epoch 14 loss: 5.378658460864411e-05\n",
      "Epoch 15 loss: 5.118150526706639e-05\n",
      "Epoch 16 loss: 4.848533660969166e-05\n",
      "Epoch 17 loss: 4.529977113080915e-05\n",
      "Epoch 18 loss: 4.3056004563956725e-05\n",
      "Epoch 19 loss: 4.131322946797562e-05\n",
      "Epoch 20 loss: 3.937627116230296e-05\n",
      "Epoch 21 loss: 3.750123115433451e-05\n",
      "Epoch 22 loss: 3.6052709494495435e-05\n",
      "Epoch 23 loss: 3.452924193136683e-05\n",
      "Epoch 24 loss: 3.3383135837478685e-05\n",
      "Epoch 25 loss: 3.214026151301775e-05\n",
      "Epoch 26 loss: 3.0983953429616376e-05\n",
      "Epoch 27 loss: 2.989390598937169e-05\n",
      "Epoch 28 loss: 2.9042381662387672e-05\n",
      "Epoch 29 loss: 2.8178825137413932e-05\n",
      "Epoch 30 loss: 2.717893803890546e-05\n",
      "\n",
      "\n",
      "Client 3 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 1.898236984265722e-10\n",
      "Epoch 1 loss: 0.02694790675961293\n",
      "Epoch 2 loss: 0.009730886208219689\n",
      "Epoch 3 loss: 0.003811111371714531\n",
      "Epoch 4 loss: 0.000450860661683019\n",
      "Epoch 5 loss: 0.0002573764483194756\n",
      "Epoch 6 loss: 0.00018874987582914902\n",
      "Epoch 7 loss: 0.0001623165966704735\n",
      "Epoch 8 loss: 0.00014089859421939396\n",
      "Epoch 9 loss: 0.00012874222982965023\n",
      "Epoch 10 loss: 0.00011507298065787854\n",
      "Epoch 11 loss: 0.0001074597780332242\n",
      "Epoch 12 loss: 9.687517950382887e-05\n",
      "Epoch 13 loss: 9.00780165206707e-05\n",
      "Epoch 14 loss: 8.42046590540598e-05\n",
      "Epoch 15 loss: 7.893124250572666e-05\n",
      "Epoch 16 loss: 7.462599456869883e-05\n",
      "Epoch 17 loss: 7.041582113396559e-05\n",
      "Epoch 18 loss: 6.692627087810153e-05\n",
      "Epoch 19 loss: 6.374898242560244e-05\n",
      "Epoch 20 loss: 6.082271116874739e-05\n",
      "Epoch 21 loss: 5.840714014784632e-05\n",
      "Epoch 22 loss: 5.585667964923948e-05\n",
      "Epoch 23 loss: 5.354127884115322e-05\n",
      "Epoch 24 loss: 5.142697012076721e-05\n",
      "Epoch 25 loss: 4.94982617344238e-05\n",
      "Epoch 26 loss: 4.7790033784239276e-05\n",
      "Epoch 27 loss: 4.617119639807422e-05\n",
      "Epoch 28 loss: 4.477043120700994e-05\n",
      "Epoch 29 loss: 4.4281844534802055e-05\n",
      "Epoch 30 loss: 4.14717635738753e-05\n",
      "\n",
      "\n",
      "Client 4 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 1.898236984265722e-10\n",
      "Epoch 1 loss: 0.030686179777234805\n",
      "Epoch 2 loss: 0.007351568094449287\n",
      "Epoch 3 loss: 0.0017629932257105271\n",
      "Epoch 4 loss: 0.0005389856433852246\n",
      "Epoch 5 loss: 0.0003879928075974099\n",
      "Epoch 6 loss: 0.0002671655969065119\n",
      "Epoch 7 loss: 0.0002188862043637644\n",
      "Epoch 8 loss: 0.00018687966771504432\n",
      "Epoch 9 loss: 0.0001691164431305995\n",
      "Epoch 10 loss: 0.00014915756754103096\n",
      "Epoch 11 loss: 0.00013487329264344128\n",
      "Epoch 12 loss: 0.00012404505164939332\n",
      "Epoch 13 loss: 0.00011480504235246348\n",
      "Epoch 14 loss: 0.00010785347406223092\n",
      "Epoch 15 loss: 0.00010154148081200064\n",
      "Epoch 16 loss: 9.369383081579667e-05\n",
      "Epoch 17 loss: 8.907333717665874e-05\n",
      "Epoch 18 loss: 8.435913070057877e-05\n",
      "Epoch 19 loss: 8.10158828889545e-05\n",
      "Epoch 20 loss: 7.597659805378741e-05\n",
      "Epoch 21 loss: 7.190358970889365e-05\n",
      "Epoch 22 loss: 6.86247186861431e-05\n",
      "Epoch 23 loss: 6.555999186533799e-05\n",
      "Epoch 24 loss: 6.292686309903884e-05\n",
      "Epoch 25 loss: 6.040987838189799e-05\n",
      "Epoch 26 loss: 5.8510266436064496e-05\n",
      "Epoch 27 loss: 5.627758557261223e-05\n",
      "Epoch 28 loss: 5.367700391401707e-05\n",
      "Epoch 29 loss: 5.2506884444519435e-05\n",
      "Epoch 30 loss: 5.010728314040138e-05\n",
      "\n",
      "\n",
      "Client 5 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 1.898236984265722e-10\n",
      "Epoch 1 loss: 0.041324286933694505\n",
      "Epoch 2 loss: 0.012289233753572843\n",
      "Epoch 3 loss: 0.00583848648519516\n",
      "Epoch 4 loss: 0.0013621258819289613\n",
      "Epoch 5 loss: 0.0006012675926866266\n",
      "Epoch 6 loss: 0.0003964387992661439\n",
      "Epoch 7 loss: 0.0002849127509167142\n",
      "Epoch 8 loss: 0.00024648381906174224\n",
      "Epoch 9 loss: 0.00020616263344059105\n",
      "Epoch 10 loss: 0.00018071454274756936\n",
      "Epoch 11 loss: 0.00016424421203693897\n",
      "Epoch 12 loss: 0.00015026936099247072\n",
      "Epoch 13 loss: 0.00013614465745635766\n",
      "Epoch 14 loss: 0.00012548222300689846\n",
      "Epoch 15 loss: 0.00011751469148422036\n",
      "Epoch 16 loss: 0.00010875676005442901\n",
      "Epoch 17 loss: 0.00010189754524898045\n",
      "Epoch 18 loss: 9.675391700443953e-05\n",
      "Epoch 19 loss: 9.10346107163751e-05\n",
      "Epoch 20 loss: 8.659766948803035e-05\n",
      "Epoch 21 loss: 8.198707904620898e-05\n",
      "Epoch 22 loss: 7.80545880004072e-05\n",
      "Epoch 23 loss: 7.499482624270508e-05\n",
      "Epoch 24 loss: 7.168560165730299e-05\n",
      "Epoch 25 loss: 6.884789753731587e-05\n",
      "Epoch 26 loss: 6.555232122935345e-05\n",
      "Epoch 27 loss: 6.340201476067695e-05\n",
      "Epoch 28 loss: 6.109560704232458e-05\n",
      "Epoch 29 loss: 5.8803975362218596e-05\n",
      "Epoch 30 loss: 5.7291833518005895e-05\n",
      "\n",
      "Accuracy of the network: 98.98, Loss: 2.847355129453888e-10\n",
      "Loss difference: 9.491181451881658e-11\n",
      "Global Round 2 ends\n",
      "\n",
      "\n",
      " ====================== Global Round 4 ======================\n",
      "Client 1 starts training...\n",
      "losss difference: 9.491181451881658e-11\n",
      "last global loss: 2.847355129453888e-10\n",
      "Epoch 1 loss: 0.0241166829515735\n",
      "Epoch 2 loss: 0.00630527664055351\n",
      "Epoch 3 loss: 0.002980029190346255\n",
      "Epoch 4 loss: 0.0010576711184171472\n",
      "Epoch 5 loss: 0.00018582464373197426\n",
      "Epoch 6 loss: 0.00012454659878841917\n",
      "Epoch 7 loss: 0.00010255281794545294\n",
      "Epoch 8 loss: 8.892496858299245e-05\n",
      "Epoch 9 loss: 7.90528818283789e-05\n",
      "Epoch 10 loss: 7.18650942615343e-05\n",
      "Epoch 11 loss: 6.549079481273002e-05\n",
      "Epoch 12 loss: 6.0410828187200954e-05\n",
      "Epoch 13 loss: 5.6047804441865335e-05\n",
      "Epoch 14 loss: 5.251611358841772e-05\n",
      "Epoch 15 loss: 4.9840491233026645e-05\n",
      "Epoch 16 loss: 4.651598355081283e-05\n",
      "Epoch 17 loss: 4.413598355027266e-05\n",
      "Epoch 18 loss: 4.191968050616698e-05\n",
      "Epoch 19 loss: 3.981242949497818e-05\n",
      "Epoch 20 loss: 3.828851051378825e-05\n",
      "Epoch 21 loss: 3.642045680862793e-05\n",
      "Epoch 22 loss: 3.503020768420053e-05\n",
      "Epoch 23 loss: 3.409194649780062e-05\n",
      "Epoch 24 loss: 3.27078534772552e-05\n",
      "Epoch 25 loss: 3.1226800265533544e-05\n",
      "Epoch 26 loss: 3.0185846963348695e-05\n",
      "Epoch 27 loss: 2.926180642163897e-05\n",
      "Epoch 28 loss: 2.823408826230813e-05\n",
      "Epoch 29 loss: 2.7479244187185123e-05\n",
      "Epoch 30 loss: 2.6645525876559875e-05\n",
      "\n",
      "\n",
      "Client 2 starts training...\n",
      "losss difference: 9.491181451881658e-11\n",
      "last global loss: 2.847355129453888e-10\n",
      "Epoch 1 loss: 0.022068137940544467\n",
      "Epoch 2 loss: 0.006611377996975118\n",
      "Epoch 3 loss: 0.0019719830998055406\n",
      "Epoch 4 loss: 0.00016433415434030296\n",
      "Epoch 5 loss: 0.00011176551293890183\n",
      "Epoch 6 loss: 9.043977447279448e-05\n",
      "Epoch 7 loss: 7.846414786036256e-05\n",
      "Epoch 8 loss: 7.00714922873387e-05\n",
      "Epoch 9 loss: 6.372354155361181e-05\n",
      "Epoch 10 loss: 5.914385573661659e-05\n",
      "Epoch 11 loss: 5.388329363354581e-05\n",
      "Epoch 12 loss: 5.025838708124101e-05\n",
      "Epoch 13 loss: 4.695769095844644e-05\n",
      "Epoch 14 loss: 4.435818019879526e-05\n",
      "Epoch 15 loss: 4.1899367915068474e-05\n",
      "Epoch 16 loss: 3.967903956782706e-05\n",
      "Epoch 17 loss: 3.790638827848746e-05\n",
      "Epoch 18 loss: 3.6110758949213715e-05\n",
      "Epoch 19 loss: 3.4678103258376597e-05\n",
      "Epoch 20 loss: 3.313007534155393e-05\n",
      "Epoch 21 loss: 3.1852882965543535e-05\n",
      "Epoch 22 loss: 3.0697065567780854e-05\n",
      "Epoch 23 loss: 2.9529525784421682e-05\n",
      "Epoch 24 loss: 2.8508045562519854e-05\n",
      "Epoch 25 loss: 2.7551050249983026e-05\n",
      "Epoch 26 loss: 2.6696490367381263e-05\n",
      "Epoch 27 loss: 2.587302916808652e-05\n",
      "Epoch 28 loss: 2.528026609069308e-05\n",
      "Epoch 29 loss: 2.4454899528911163e-05\n",
      "Epoch 30 loss: 2.3683080899326355e-05\n",
      "\n",
      "\n",
      "Client 3 starts training...\n",
      "losss difference: 9.491181451881658e-11\n",
      "last global loss: 2.847355129453888e-10\n",
      "Epoch 1 loss: 0.021890672393936335\n",
      "Epoch 2 loss: 0.005450403027976607\n",
      "Epoch 3 loss: 0.0014474930172313895\n",
      "Epoch 4 loss: 0.000995911159095534\n",
      "Epoch 5 loss: 0.00018647857292033347\n",
      "Epoch 6 loss: 0.00013766549678449492\n",
      "Epoch 7 loss: 0.0001165759984771703\n",
      "Epoch 8 loss: 0.00010184523372596169\n",
      "Epoch 9 loss: 9.077767391738932e-05\n",
      "Epoch 10 loss: 8.196576346258457e-05\n",
      "Epoch 11 loss: 7.530563070220746e-05\n",
      "Epoch 12 loss: 6.911283423023101e-05\n",
      "Epoch 13 loss: 6.444850342056593e-05\n",
      "Epoch 14 loss: 6.040981968075003e-05\n",
      "Epoch 15 loss: 5.713623416351737e-05\n",
      "Epoch 16 loss: 5.3702180635056e-05\n",
      "Epoch 17 loss: 5.0880270153371496e-05\n",
      "Epoch 18 loss: 4.8500773585720086e-05\n",
      "Epoch 19 loss: 4.6139531599215595e-05\n",
      "Epoch 20 loss: 4.4173470331724703e-05\n",
      "Epoch 21 loss: 4.232315538736033e-05\n",
      "Epoch 22 loss: 4.054577149970749e-05\n",
      "Epoch 23 loss: 4.0031175711560614e-05\n",
      "Epoch 24 loss: 3.758237471236334e-05\n",
      "Epoch 25 loss: 3.616694422899937e-05\n",
      "Epoch 26 loss: 3.497876132497108e-05\n",
      "Epoch 27 loss: 3.3777885102508625e-05\n",
      "Epoch 28 loss: 3.2679692253774394e-05\n",
      "Epoch 29 loss: 3.16652754985541e-05\n",
      "Epoch 30 loss: 3.0716394723550905e-05\n",
      "\n",
      "\n",
      "Client 4 starts training...\n",
      "losss difference: 9.491181451881658e-11\n",
      "last global loss: 2.847355129453888e-10\n",
      "Epoch 1 loss: 0.02499782569383723\n",
      "Epoch 2 loss: 0.004442518603899229\n",
      "Epoch 3 loss: 0.0010017315072034646\n",
      "Epoch 4 loss: 0.0002798234900923939\n",
      "Epoch 5 loss: 0.00020479200707890693\n",
      "Epoch 6 loss: 0.000167279915633523\n",
      "Epoch 7 loss: 0.00015714718674771235\n",
      "Epoch 8 loss: 0.00013379034134294805\n",
      "Epoch 9 loss: 0.00011613438722539537\n",
      "Epoch 10 loss: 0.00010532370443807521\n",
      "Epoch 11 loss: 9.712401703063976e-05\n",
      "Epoch 12 loss: 9.159537909033346e-05\n",
      "Epoch 13 loss: 8.34683618617276e-05\n",
      "Epoch 14 loss: 7.768259037700705e-05\n",
      "Epoch 15 loss: 7.350116675872094e-05\n",
      "Epoch 16 loss: 6.899465338824846e-05\n",
      "Epoch 17 loss: 6.559483517398295e-05\n",
      "Epoch 18 loss: 6.214205509734184e-05\n",
      "Epoch 19 loss: 5.906684787360826e-05\n",
      "Epoch 20 loss: 5.660332090200732e-05\n",
      "Epoch 21 loss: 5.423475822482033e-05\n",
      "Epoch 22 loss: 5.210700532780657e-05\n",
      "Epoch 23 loss: 5.068207489411266e-05\n",
      "Epoch 24 loss: 4.8307471333066343e-05\n",
      "Epoch 25 loss: 4.623137223772351e-05\n",
      "Epoch 26 loss: 4.471183972587737e-05\n",
      "Epoch 27 loss: 4.329179996531707e-05\n",
      "Epoch 28 loss: 4.163946371659343e-05\n",
      "Epoch 29 loss: 4.067599793762444e-05\n",
      "Epoch 30 loss: 3.912991539451732e-05\n",
      "\n",
      "\n",
      "Client 5 dropped\n",
      "Accuracy of the network: 99.13, Loss: 9.49118492132861e-11\n",
      "Loss difference: -1.8982365679320878e-10\n",
      "Global Round 3 ends\n",
      "\n",
      "\n",
      " ====================== Global Round 5 ======================\n",
      "Client 1 starts training...\n",
      "losss difference: -1.8982365679320878e-10\n",
      "last global loss: 9.49118492132861e-11\n",
      "Epoch 1 loss: 0.013623984864039434\n",
      "Epoch 2 loss: 0.002911146862783924\n",
      "Epoch 3 loss: 0.0007794704855013196\n",
      "Epoch 4 loss: 0.00014729368003598366\n",
      "Epoch 5 loss: 8.205429365648373e-05\n",
      "Epoch 6 loss: 6.98159276009514e-05\n",
      "Epoch 7 loss: 6.114115263350963e-05\n",
      "Epoch 8 loss: 5.5208213335590774e-05\n",
      "Epoch 9 loss: 5.015494481672806e-05\n",
      "Epoch 10 loss: 4.6647094835006414e-05\n",
      "Epoch 11 loss: 4.3469306823569386e-05\n",
      "Epoch 12 loss: 4.063021328580995e-05\n",
      "Epoch 13 loss: 3.808824620935782e-05\n",
      "Epoch 14 loss: 3.6442013925041385e-05\n",
      "Epoch 15 loss: 3.434623016084381e-05\n",
      "Epoch 16 loss: 3.2889517572804246e-05\n",
      "Epoch 17 loss: 3.1303235400067306e-05\n",
      "Epoch 18 loss: 2.9887958894167686e-05\n",
      "Epoch 19 loss: 2.8625551630015515e-05\n",
      "Epoch 20 loss: 2.7591541215079233e-05\n",
      "Epoch 21 loss: 2.6838690224934604e-05\n",
      "Epoch 22 loss: 2.557520679166171e-05\n",
      "Epoch 23 loss: 2.4778176545901544e-05\n",
      "Epoch 24 loss: 2.3925948825616477e-05\n",
      "Epoch 25 loss: 2.3034782004191687e-05\n",
      "Epoch 26 loss: 2.2326874754606037e-05\n",
      "Epoch 27 loss: 2.1963254305129695e-05\n",
      "Epoch 28 loss: 2.1073333883822774e-05\n",
      "Epoch 29 loss: 2.036601530838674e-05\n",
      "Epoch 30 loss: 1.9814277155273704e-05\n",
      "\n",
      "\n",
      "Client 2 starts training...\n",
      "losss difference: -1.8982365679320878e-10\n",
      "last global loss: 9.49118492132861e-11\n",
      "Epoch 1 loss: 0.012425881643656099\n",
      "Epoch 2 loss: 0.0038033770668203684\n",
      "Epoch 3 loss: 0.00307148099130383\n",
      "Epoch 4 loss: 0.0004991051391940307\n",
      "Epoch 5 loss: 0.0002798439784474821\n",
      "Epoch 6 loss: 7.25476231885654e-05\n",
      "Epoch 7 loss: 5.834103298709845e-05\n",
      "Epoch 8 loss: 5.0790825607020426e-05\n",
      "Epoch 9 loss: 4.5150961260161015e-05\n",
      "Epoch 10 loss: 4.094248253426439e-05\n",
      "Epoch 11 loss: 3.761833818645333e-05\n",
      "Epoch 12 loss: 3.5030152748305454e-05\n",
      "Epoch 13 loss: 3.254519085720087e-05\n",
      "Epoch 14 loss: 3.0639705399912394e-05\n",
      "Epoch 15 loss: 2.8872782740493106e-05\n",
      "Epoch 16 loss: 2.734875719355877e-05\n",
      "Epoch 17 loss: 2.59958706608469e-05\n",
      "Epoch 18 loss: 2.487518279699489e-05\n",
      "Epoch 19 loss: 2.3808075817505804e-05\n",
      "Epoch 20 loss: 2.272042297262e-05\n",
      "Epoch 21 loss: 2.1819733320619112e-05\n",
      "Epoch 22 loss: 2.098693578480251e-05\n",
      "Epoch 23 loss: 2.0305675672611844e-05\n",
      "Epoch 24 loss: 1.955190034793868e-05\n",
      "Epoch 25 loss: 1.906885543277932e-05\n",
      "Epoch 26 loss: 1.835690831799244e-05\n",
      "Epoch 27 loss: 1.7708845121148444e-05\n",
      "Epoch 28 loss: 1.7299320424497982e-05\n",
      "Epoch 29 loss: 1.6687890340667486e-05\n",
      "Epoch 30 loss: 1.6347228400627497e-05\n",
      "\n",
      "\n",
      "Client 3 starts training...\n",
      "losss difference: -1.8982365679320878e-10\n",
      "last global loss: 9.49118492132861e-11\n",
      "Epoch 1 loss: 0.011500397262465717\n",
      "Epoch 2 loss: 0.0036560962037636736\n",
      "Epoch 3 loss: 0.00031829657075103316\n",
      "Epoch 4 loss: 0.0001151688023344105\n",
      "Epoch 5 loss: 7.591264160211608e-05\n",
      "Epoch 6 loss: 6.627826077209186e-05\n",
      "Epoch 7 loss: 5.901868713028108e-05\n",
      "Epoch 8 loss: 5.34608597596032e-05\n",
      "Epoch 9 loss: 4.880779223716299e-05\n",
      "Epoch 10 loss: 4.529757884802831e-05\n",
      "Epoch 11 loss: 4.227039366265004e-05\n",
      "Epoch 12 loss: 3.973046841365207e-05\n",
      "Epoch 13 loss: 3.75238198752401e-05\n",
      "Epoch 14 loss: 3.5564903656937446e-05\n",
      "Epoch 15 loss: 3.388637015365429e-05\n",
      "Epoch 16 loss: 3.229085217861002e-05\n",
      "Epoch 17 loss: 3.082523828621492e-05\n",
      "Epoch 18 loss: 2.9727988909802234e-05\n",
      "Epoch 19 loss: 2.8545830591082117e-05\n",
      "Epoch 20 loss: 2.7406547159638434e-05\n",
      "Epoch 21 loss: 2.6309498291568538e-05\n",
      "Epoch 22 loss: 2.5538383927773625e-05\n",
      "Epoch 23 loss: 2.4561529735341656e-05\n",
      "Epoch 24 loss: 2.39701129745974e-05\n",
      "Epoch 25 loss: 2.3059934089107696e-05\n",
      "Epoch 26 loss: 2.236228913094531e-05\n",
      "Epoch 27 loss: 2.1887839381480974e-05\n",
      "Epoch 28 loss: 2.1043822810143446e-05\n",
      "Epoch 29 loss: 2.048436461595119e-05\n",
      "Epoch 30 loss: 1.9899224229405074e-05\n",
      "\n",
      "\n",
      "Client 4 starts training...\n",
      "losss difference: -1.8982365679320878e-10\n",
      "last global loss: 9.49118492132861e-11\n",
      "Epoch 1 loss: 0.016050655272230284\n",
      "Epoch 2 loss: 0.0021279858755323925\n",
      "Epoch 3 loss: 0.001538583924605124\n",
      "Epoch 4 loss: 0.00038821727255277977\n",
      "Epoch 5 loss: 0.00012678170585960733\n",
      "Epoch 6 loss: 9.978210930530573e-05\n",
      "Epoch 7 loss: 8.552207189833108e-05\n",
      "Epoch 8 loss: 7.657093158362032e-05\n",
      "Epoch 9 loss: 6.890237699175767e-05\n",
      "Epoch 10 loss: 6.327234027388783e-05\n",
      "Epoch 11 loss: 5.8881793671254004e-05\n",
      "Epoch 12 loss: 5.4892534847267185e-05\n",
      "Epoch 13 loss: 5.1461575029247316e-05\n",
      "Epoch 14 loss: 4.8465829057824654e-05\n",
      "Epoch 15 loss: 4.57727651829047e-05\n",
      "Epoch 16 loss: 4.350575295560136e-05\n",
      "Epoch 17 loss: 4.1925897232553603e-05\n",
      "Epoch 18 loss: 3.9766287899507015e-05\n",
      "Epoch 19 loss: 3.781248851753725e-05\n",
      "Epoch 20 loss: 3.637203911895004e-05\n",
      "Epoch 21 loss: 3.493736775348808e-05\n",
      "Epoch 22 loss: 3.369382218535184e-05\n",
      "Epoch 23 loss: 3.288816234912629e-05\n",
      "Epoch 24 loss: 3.128396933365132e-05\n",
      "Epoch 25 loss: 3.0371205977632782e-05\n",
      "Epoch 26 loss: 2.933434417686456e-05\n",
      "Epoch 27 loss: 2.8425133984245454e-05\n",
      "Epoch 28 loss: 2.7544920221073013e-05\n",
      "Epoch 29 loss: 2.6870218958648256e-05\n",
      "Epoch 30 loss: 2.634178472104175e-05\n",
      "\n",
      "\n",
      "Client 5 starts training...\n",
      "losss difference: -1.8982365679320878e-10\n",
      "last global loss: 9.49118492132861e-11\n",
      "Epoch 1 loss: 0.03159212414051426\n",
      "Epoch 2 loss: 0.008628953152389327\n",
      "Epoch 3 loss: 0.0022552632306773214\n",
      "Epoch 4 loss: 0.0005528886633431011\n",
      "Epoch 5 loss: 0.0002440812791806207\n",
      "Epoch 6 loss: 0.0001815413021198707\n",
      "Epoch 7 loss: 0.00015361609564539766\n",
      "Epoch 8 loss: 0.00013394407332513724\n",
      "Epoch 9 loss: 0.00011857796108987704\n",
      "Epoch 10 loss: 0.00010714656969925117\n",
      "Epoch 11 loss: 9.881434118315527e-05\n",
      "Epoch 12 loss: 9.084739766023481e-05\n",
      "Epoch 13 loss: 8.441834464058066e-05\n",
      "Epoch 14 loss: 7.852425015562615e-05\n",
      "Epoch 15 loss: 7.330192164394044e-05\n",
      "Epoch 16 loss: 6.960390630235314e-05\n",
      "Epoch 17 loss: 6.507994279610458e-05\n",
      "Epoch 18 loss: 6.162712418577658e-05\n",
      "Epoch 19 loss: 5.907898464160548e-05\n",
      "Epoch 20 loss: 5.578294450653866e-05\n",
      "Epoch 21 loss: 5.3132258669926555e-05\n",
      "Epoch 22 loss: 5.075641627119532e-05\n",
      "Epoch 23 loss: 4.876972158589321e-05\n",
      "Epoch 24 loss: 4.780717199567557e-05\n",
      "Epoch 25 loss: 4.499340830047998e-05\n",
      "Epoch 26 loss: 4.3307583888154844e-05\n",
      "Epoch 27 loss: 4.18412020017155e-05\n",
      "Epoch 28 loss: 4.0334407956302336e-05\n",
      "Epoch 29 loss: 3.913974029314248e-05\n",
      "Epoch 30 loss: 3.788742541966762e-05\n",
      "\n",
      "Accuracy of the network: 98.95, Loss: 0.0\n",
      "Loss difference: -9.49118492132861e-11\n",
      "Global Round 4 ends\n",
      "\n",
      "\n",
      " ====================== Global Round 6 ======================\n",
      "Client 1 dropped\n",
      "Client 2 starts training...\n",
      "losss difference: -9.49118492132861e-11\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.007448137960934939\n",
      "Epoch 2 loss: 0.0013778396981962563\n",
      "Epoch 3 loss: 0.00018235369073177945\n",
      "Epoch 4 loss: 8.095129774544228e-05\n",
      "Epoch 5 loss: 5.838023264996167e-05\n",
      "Epoch 6 loss: 5.09632687214466e-05\n",
      "Epoch 7 loss: 4.5207927049041377e-05\n",
      "Epoch 8 loss: 4.111902812455314e-05\n",
      "Epoch 9 loss: 3.77962581390587e-05\n",
      "Epoch 10 loss: 3.528928521680979e-05\n",
      "Epoch 11 loss: 3.289363468652748e-05\n",
      "Epoch 12 loss: 3.088862562354194e-05\n",
      "Epoch 13 loss: 2.933393878568294e-05\n",
      "Epoch 14 loss: 2.760879594802192e-05\n",
      "Epoch 15 loss: 2.6238044003465116e-05\n",
      "Epoch 16 loss: 2.5031967742153968e-05\n",
      "Epoch 17 loss: 2.3885137604197624e-05\n",
      "Epoch 18 loss: 2.2899174314329503e-05\n",
      "Epoch 19 loss: 2.218259606110298e-05\n",
      "Epoch 20 loss: 2.14074221399842e-05\n",
      "Epoch 21 loss: 2.041032676381839e-05\n",
      "Epoch 22 loss: 1.97313051155951e-05\n",
      "Epoch 23 loss: 1.9015856664991196e-05\n",
      "Epoch 24 loss: 1.840531195260825e-05\n",
      "Epoch 25 loss: 1.7812854850129247e-05\n",
      "Epoch 26 loss: 1.7296864051038734e-05\n",
      "Epoch 27 loss: 1.6788678900917013e-05\n",
      "Epoch 28 loss: 1.633855378888699e-05\n",
      "Epoch 29 loss: 1.5869715374270967e-05\n",
      "Epoch 30 loss: 1.5437348729448335e-05\n",
      "\n",
      "\n",
      "Client 3 dropped\n",
      "Client 4 starts training...\n",
      "losss difference: -9.49118492132861e-11\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.008801328451817443\n",
      "Epoch 2 loss: 0.0030776106181802944\n",
      "Epoch 3 loss: 0.00032670439834385826\n",
      "Epoch 4 loss: 0.00016569824678229337\n",
      "Epoch 5 loss: 8.378613539694837e-05\n",
      "Epoch 6 loss: 7.126068000626495e-05\n",
      "Epoch 7 loss: 6.351160743565924e-05\n",
      "Epoch 8 loss: 5.843822182455862e-05\n",
      "Epoch 9 loss: 5.293140998657735e-05\n",
      "Epoch 10 loss: 4.889857913660327e-05\n",
      "Epoch 11 loss: 4.579759677096234e-05\n",
      "Epoch 12 loss: 4.2632206796429754e-05\n",
      "Epoch 13 loss: 4.009855947532091e-05\n",
      "Epoch 14 loss: 3.7963313632601175e-05\n",
      "Epoch 15 loss: 3.614596611862997e-05\n",
      "Epoch 16 loss: 3.434757628320632e-05\n",
      "Epoch 17 loss: 3.308060453934741e-05\n",
      "Epoch 18 loss: 3.15305280521334e-05\n",
      "Epoch 19 loss: 3.0137425454881547e-05\n",
      "Epoch 20 loss: 2.9137399246618627e-05\n",
      "Epoch 21 loss: 2.7909284476644088e-05\n",
      "Epoch 22 loss: 2.6984374765266683e-05\n",
      "Epoch 23 loss: 2.592495570878975e-05\n",
      "Epoch 24 loss: 2.504582941111085e-05\n",
      "Epoch 25 loss: 2.426929168507437e-05\n",
      "Epoch 26 loss: 2.3611472217448573e-05\n",
      "Epoch 27 loss: 2.287679779368364e-05\n",
      "Epoch 28 loss: 2.220877247654955e-05\n",
      "Epoch 29 loss: 2.1679524875145927e-05\n",
      "Epoch 30 loss: 2.1091494061024038e-05\n",
      "\n",
      "\n",
      "Client 5 starts training...\n",
      "losss difference: -9.49118492132861e-11\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.012000278130991146\n",
      "Epoch 2 loss: 0.0055662511515515625\n",
      "Epoch 3 loss: 0.0010763543039068529\n",
      "Epoch 4 loss: 0.00019342835981050785\n",
      "Epoch 5 loss: 0.00011795508855285827\n",
      "Epoch 6 loss: 9.358815095535957e-05\n",
      "Epoch 7 loss: 8.1433790523202e-05\n",
      "Epoch 8 loss: 7.229717969075768e-05\n",
      "Epoch 9 loss: 6.528735046296614e-05\n",
      "Epoch 10 loss: 5.9618549296386206e-05\n",
      "Epoch 11 loss: 5.4907596204459345e-05\n",
      "Epoch 12 loss: 5.104271252564365e-05\n",
      "Epoch 13 loss: 4.7756840687608634e-05\n",
      "Epoch 14 loss: 4.502280859675787e-05\n",
      "Epoch 15 loss: 4.2333949007731336e-05\n",
      "Epoch 16 loss: 4.0401528288063016e-05\n",
      "Epoch 17 loss: 3.824339323685724e-05\n",
      "Epoch 18 loss: 3.61398482618367e-05\n",
      "Epoch 19 loss: 3.452422350461466e-05\n",
      "Epoch 20 loss: 3.3099490041908734e-05\n",
      "Epoch 21 loss: 3.1552713609883654e-05\n",
      "Epoch 22 loss: 3.0268438677015478e-05\n",
      "Epoch 23 loss: 2.9105636271654467e-05\n",
      "Epoch 24 loss: 2.800383133670618e-05\n",
      "Epoch 25 loss: 2.7148270154635548e-05\n",
      "Epoch 26 loss: 2.6133959354215743e-05\n",
      "Epoch 27 loss: 2.5234930952827105e-05\n",
      "Epoch 28 loss: 2.4483630603546417e-05\n",
      "Epoch 29 loss: 2.386773147436464e-05\n",
      "Epoch 30 loss: 2.297723894128133e-05\n",
      "\n",
      "Accuracy of the network: 98.91, Loss: 0.0\n",
      "Loss difference: 0.0\n",
      "Global Round 5 ends\n",
      "\n",
      "\n",
      " ====================== Global Round 7 ======================\n",
      "Client 1 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.011958688567202223\n",
      "Epoch 2 loss: 0.004401645500205755\n",
      "Epoch 3 loss: 0.002556501185428967\n",
      "Epoch 4 loss: 0.00014844158135105394\n",
      "Epoch 5 loss: 6.374099048355341e-05\n",
      "Epoch 6 loss: 5.24511420122513e-05\n",
      "Epoch 7 loss: 4.589650500855306e-05\n",
      "Epoch 8 loss: 4.110080320952921e-05\n",
      "Epoch 9 loss: 3.745207736883875e-05\n",
      "Epoch 10 loss: 3.459132585000644e-05\n",
      "Epoch 11 loss: 3.226229978776593e-05\n",
      "Epoch 12 loss: 3.0200284259624434e-05\n",
      "Epoch 13 loss: 2.89456451256492e-05\n",
      "Epoch 14 loss: 2.6961789090078437e-05\n",
      "Epoch 15 loss: 2.5604603136802316e-05\n",
      "Epoch 16 loss: 2.4455297639409632e-05\n",
      "Epoch 17 loss: 2.343002089407293e-05\n",
      "Epoch 18 loss: 2.2531455617267894e-05\n",
      "Epoch 19 loss: 2.158218437916077e-05\n",
      "Epoch 20 loss: 2.0827193129460272e-05\n",
      "Epoch 21 loss: 2.0037214304450008e-05\n",
      "Epoch 22 loss: 1.937718679843851e-05\n",
      "Epoch 23 loss: 1.871486374771702e-05\n",
      "Epoch 24 loss: 1.8252772768610255e-05\n",
      "Epoch 25 loss: 1.7542334275053678e-05\n",
      "Epoch 26 loss: 1.708111294564137e-05\n",
      "Epoch 27 loss: 1.662481643867017e-05\n",
      "Epoch 28 loss: 1.6079370318135307e-05\n",
      "Epoch 29 loss: 1.5798889475550624e-05\n",
      "Epoch 30 loss: 1.5232128180841603e-05\n",
      "\n",
      "\n",
      "Client 2 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.007810808288310893\n",
      "Epoch 2 loss: 0.004494334272062827\n",
      "Epoch 3 loss: 0.0008478037375831357\n",
      "Epoch 4 loss: 0.000482514920172547\n",
      "Epoch 5 loss: 5.72403202120635e-05\n",
      "Epoch 6 loss: 3.503943411312636e-05\n",
      "Epoch 7 loss: 2.916388740528745e-05\n",
      "Epoch 8 loss: 2.5817996019239982e-05\n",
      "Epoch 9 loss: 2.3617812026320308e-05\n",
      "Epoch 10 loss: 2.1771213086738777e-05\n",
      "Epoch 11 loss: 2.0225905668508468e-05\n",
      "Epoch 12 loss: 1.9208345296325685e-05\n",
      "Epoch 13 loss: 1.845571952268076e-05\n",
      "Epoch 14 loss: 1.7174078425135596e-05\n",
      "Epoch 15 loss: 1.6278288152006578e-05\n",
      "Epoch 16 loss: 1.54803768413209e-05\n",
      "Epoch 17 loss: 1.4839744465803958e-05\n",
      "Epoch 18 loss: 1.4249022318453689e-05\n",
      "Epoch 19 loss: 1.3718768114540683e-05\n",
      "Epoch 20 loss: 1.3224595497845693e-05\n",
      "Epoch 21 loss: 1.2779869074741838e-05\n",
      "Epoch 22 loss: 1.2362154077568474e-05\n",
      "Epoch 23 loss: 1.1991360681680353e-05\n",
      "Epoch 24 loss: 1.1626405457837323e-05\n",
      "Epoch 25 loss: 1.1299072758659693e-05\n",
      "Epoch 26 loss: 1.097134068818362e-05\n",
      "Epoch 27 loss: 1.0681134324407954e-05\n",
      "Epoch 28 loss: 1.0486374628023496e-05\n",
      "Epoch 29 loss: 1.0307647626503431e-05\n",
      "Epoch 30 loss: 9.954994430852637e-06\n",
      "\n",
      "\n",
      "Client 3 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.012564027401884219\n",
      "Epoch 2 loss: 0.0024155273286112448\n",
      "Epoch 3 loss: 0.0014568535621419792\n",
      "Epoch 4 loss: 0.00011322477289265455\n",
      "Epoch 5 loss: 6.154272746645187e-05\n",
      "Epoch 6 loss: 5.1705948823780775e-05\n",
      "Epoch 7 loss: 4.597246818008858e-05\n",
      "Epoch 8 loss: 4.086277388766166e-05\n",
      "Epoch 9 loss: 3.747362076239484e-05\n",
      "Epoch 10 loss: 3.48677131219361e-05\n",
      "Epoch 11 loss: 3.332497381290567e-05\n",
      "Epoch 12 loss: 3.052573219974402e-05\n",
      "Epoch 13 loss: 2.8916009416707945e-05\n",
      "Epoch 14 loss: 2.721929269637218e-05\n",
      "Epoch 15 loss: 2.5907985205834125e-05\n",
      "Epoch 16 loss: 2.5437109625458143e-05\n",
      "Epoch 17 loss: 2.3645288694773204e-05\n",
      "Epoch 18 loss: 2.2722507291728563e-05\n",
      "Epoch 19 loss: 2.187513639902781e-05\n",
      "Epoch 20 loss: 2.108479547673631e-05\n",
      "Epoch 21 loss: 2.035046075034799e-05\n",
      "Epoch 22 loss: 1.9703475492242264e-05\n",
      "Epoch 23 loss: 1.908147167139519e-05\n",
      "Epoch 24 loss: 1.8471510428439278e-05\n",
      "Epoch 25 loss: 1.7941456982968058e-05\n",
      "Epoch 26 loss: 1.751291211446873e-05\n",
      "Epoch 27 loss: 1.6982261035860676e-05\n",
      "Epoch 28 loss: 1.650396067011897e-05\n",
      "Epoch 29 loss: 1.596217229550054e-05\n",
      "Epoch 30 loss: 1.5653632885484787e-05\n",
      "\n",
      "\n",
      "Client 4 dropped\n",
      "Client 5 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.010222585057636811\n",
      "Epoch 2 loss: 0.0026310124153821153\n",
      "Epoch 3 loss: 0.0003627383944325311\n",
      "Epoch 4 loss: 0.00012229707488985845\n",
      "Epoch 5 loss: 8.075132544676948e-05\n",
      "Epoch 6 loss: 6.536430365345265e-05\n",
      "Epoch 7 loss: 5.766437982745772e-05\n",
      "Epoch 8 loss: 5.137165738617546e-05\n",
      "Epoch 9 loss: 4.6842655839616315e-05\n",
      "Epoch 10 loss: 4.305129885123416e-05\n",
      "Epoch 11 loss: 4.0029101399075245e-05\n",
      "Epoch 12 loss: 3.7414264388611865e-05\n",
      "Epoch 13 loss: 3.5175704312232235e-05\n",
      "Epoch 14 loss: 3.337107576443445e-05\n",
      "Epoch 15 loss: 3.1613809688240883e-05\n",
      "Epoch 16 loss: 3.0213765350912644e-05\n",
      "Epoch 17 loss: 2.8706021413443216e-05\n",
      "Epoch 18 loss: 2.7532433301640756e-05\n",
      "Epoch 19 loss: 2.6329681862695025e-05\n",
      "Epoch 20 loss: 2.5345588085083488e-05\n",
      "Epoch 21 loss: 2.44364471860896e-05\n",
      "Epoch 22 loss: 2.3842548344660144e-05\n",
      "Epoch 23 loss: 2.2700322365956235e-05\n",
      "Epoch 24 loss: 2.1978935711204068e-05\n",
      "Epoch 25 loss: 2.1354237251585422e-05\n",
      "Epoch 26 loss: 2.091430513771723e-05\n",
      "Epoch 27 loss: 2.0042936849360756e-05\n",
      "Epoch 28 loss: 1.9724135320884445e-05\n",
      "Epoch 29 loss: 1.8963699158201282e-05\n",
      "Epoch 30 loss: 1.8635807975538428e-05\n",
      "\n",
      "Accuracy of the network: 99.09, Loss: 0.0\n",
      "Loss difference: 0.0\n",
      "Global Round 6 ends\n",
      "\n",
      "\n",
      " ====================== Global Round 8 ======================\n",
      "Client 1 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.008762269689183593\n",
      "Epoch 2 loss: 0.0013258599504282114\n",
      "Epoch 3 loss: 0.0012705150093338415\n",
      "Epoch 4 loss: 0.0002230164946192772\n",
      "Epoch 5 loss: 5.437467767359933e-05\n",
      "Epoch 6 loss: 4.038445527689389e-05\n",
      "Epoch 7 loss: 3.5194562431714295e-05\n",
      "Epoch 8 loss: 3.1569517999224686e-05\n",
      "Epoch 9 loss: 2.900219141746009e-05\n",
      "Epoch 10 loss: 2.709951116093479e-05\n",
      "Epoch 11 loss: 2.5006843460331124e-05\n",
      "Epoch 12 loss: 2.3384100305785953e-05\n",
      "Epoch 13 loss: 2.206709679032194e-05\n",
      "Epoch 14 loss: 2.0928610943278674e-05\n",
      "Epoch 15 loss: 1.9958054337462014e-05\n",
      "Epoch 16 loss: 1.9070727966557476e-05\n",
      "Epoch 17 loss: 1.8273710787557744e-05\n",
      "Epoch 18 loss: 1.7753844659069424e-05\n",
      "Epoch 19 loss: 1.683307523467525e-05\n",
      "Epoch 20 loss: 1.6201059227231243e-05\n",
      "Epoch 21 loss: 1.5648802541156957e-05\n",
      "Epoch 22 loss: 1.5125093113117684e-05\n",
      "Epoch 23 loss: 1.4956598404563266e-05\n",
      "Epoch 24 loss: 1.4201375791981195e-05\n",
      "Epoch 25 loss: 1.3961745668316968e-05\n",
      "Epoch 26 loss: 1.3390488784740464e-05\n",
      "Epoch 27 loss: 1.3060840416744787e-05\n",
      "Epoch 28 loss: 1.2707177531800825e-05\n",
      "Epoch 29 loss: 1.2406170921237241e-05\n",
      "Epoch 30 loss: 1.2116458594232878e-05\n",
      "\n",
      "\n",
      "Client 2 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.002315571023668138\n",
      "Epoch 2 loss: 0.001886383080838051\n",
      "Epoch 3 loss: 0.002002457820188788\n",
      "Epoch 4 loss: 0.00012665737938976002\n",
      "Epoch 5 loss: 4.2059954071714385e-05\n",
      "Epoch 6 loss: 3.296944678145434e-05\n",
      "Epoch 7 loss: 2.880534030967578e-05\n",
      "Epoch 8 loss: 2.5995447267942238e-05\n",
      "Epoch 9 loss: 2.3745666184044646e-05\n",
      "Epoch 10 loss: 2.1995891239873103e-05\n",
      "Epoch 11 loss: 2.058234528108335e-05\n",
      "Epoch 12 loss: 1.9324665206937046e-05\n",
      "Epoch 13 loss: 1.831238054781926e-05\n",
      "Epoch 14 loss: 1.734555323450625e-05\n",
      "Epoch 15 loss: 1.651823847398961e-05\n",
      "Epoch 16 loss: 1.5835362538366444e-05\n",
      "Epoch 17 loss: 1.522853349988445e-05\n",
      "Epoch 18 loss: 1.4546192125854857e-05\n",
      "Epoch 19 loss: 1.3985231293920234e-05\n",
      "Epoch 20 loss: 1.34817020219567e-05\n",
      "Epoch 21 loss: 1.304836755796588e-05\n",
      "Epoch 22 loss: 1.2622650098058087e-05\n",
      "Epoch 23 loss: 1.2174141401889745e-05\n",
      "Epoch 24 loss: 1.1787252675311625e-05\n",
      "Epoch 25 loss: 1.14419546557236e-05\n",
      "Epoch 26 loss: 1.1135390928829675e-05\n",
      "Epoch 27 loss: 1.0792793441617975e-05\n",
      "Epoch 28 loss: 1.0526293911882485e-05\n",
      "Epoch 29 loss: 1.0267121489938061e-05\n",
      "Epoch 30 loss: 9.987346297669927e-06\n",
      "\n",
      "\n",
      "Client 3 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.007136817939207691\n",
      "Epoch 2 loss: 0.0021994638109619235\n",
      "Epoch 3 loss: 0.00018839904499665992\n",
      "Epoch 4 loss: 6.108508172387326e-05\n",
      "Epoch 5 loss: 4.9649320823642194e-05\n",
      "Epoch 6 loss: 4.3030235467218463e-05\n",
      "Epoch 7 loss: 3.833862445402459e-05\n",
      "Epoch 8 loss: 3.504525936414078e-05\n",
      "Epoch 9 loss: 3.198582236984159e-05\n",
      "Epoch 10 loss: 2.9651370511608906e-05\n",
      "Epoch 11 loss: 2.791946769887172e-05\n",
      "Epoch 12 loss: 2.600288708416632e-05\n",
      "Epoch 13 loss: 2.455627464305775e-05\n",
      "Epoch 14 loss: 2.3510552021584107e-05\n",
      "Epoch 15 loss: 2.213988484985436e-05\n",
      "Epoch 16 loss: 2.1396667726638524e-05\n",
      "Epoch 17 loss: 2.031810350022874e-05\n",
      "Epoch 18 loss: 1.962774878054899e-05\n",
      "Epoch 19 loss: 1.8704312636546086e-05\n",
      "Epoch 20 loss: 1.8020769981075742e-05\n",
      "Epoch 21 loss: 1.736572264903722e-05\n",
      "Epoch 22 loss: 1.6865647431510952e-05\n",
      "Epoch 23 loss: 1.6245726195917657e-05\n",
      "Epoch 24 loss: 1.582833265036966e-05\n",
      "Epoch 25 loss: 1.5496946662996405e-05\n",
      "Epoch 26 loss: 1.4856268564578821e-05\n",
      "Epoch 27 loss: 1.4432974659200077e-05\n",
      "Epoch 28 loss: 1.4058266724807732e-05\n",
      "Epoch 29 loss: 1.3703900735168146e-05\n",
      "Epoch 30 loss: 1.3353812915103663e-05\n",
      "\n",
      "\n",
      "Client 4 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.01446779910375861\n",
      "Epoch 2 loss: 0.003099960707051411\n",
      "Epoch 3 loss: 0.0008412846910078952\n",
      "Epoch 4 loss: 0.00011007075263094332\n",
      "Epoch 5 loss: 6.871477887739093e-05\n",
      "Epoch 6 loss: 5.6405149491605184e-05\n",
      "Epoch 7 loss: 4.9599644481718044e-05\n",
      "Epoch 8 loss: 4.463080683059937e-05\n",
      "Epoch 9 loss: 4.185531740351799e-05\n",
      "Epoch 10 loss: 3.7720036902359374e-05\n",
      "Epoch 11 loss: 3.506781844893484e-05\n",
      "Epoch 12 loss: 3.3340052208048664e-05\n",
      "Epoch 13 loss: 3.1464788540481096e-05\n",
      "Epoch 14 loss: 2.9718910326812838e-05\n",
      "Epoch 15 loss: 2.8302451901653357e-05\n",
      "Epoch 16 loss: 2.7140438056251996e-05\n",
      "Epoch 17 loss: 2.593315449283386e-05\n",
      "Epoch 18 loss: 2.4925523686461328e-05\n",
      "Epoch 19 loss: 2.3984528836538924e-05\n",
      "Epoch 20 loss: 2.31646165644483e-05\n",
      "Epoch 21 loss: 2.235618471063801e-05\n",
      "Epoch 22 loss: 2.1656595069951865e-05\n",
      "Epoch 23 loss: 2.0963175288063343e-05\n",
      "Epoch 24 loss: 2.0275788862100796e-05\n",
      "Epoch 25 loss: 1.9667625920977978e-05\n",
      "Epoch 26 loss: 1.9129347601679827e-05\n",
      "Epoch 27 loss: 1.8656153211464666e-05\n",
      "Epoch 28 loss: 1.8125131148055815e-05\n",
      "Epoch 29 loss: 1.7679297666783415e-05\n",
      "Epoch 30 loss: 1.729028621218357e-05\n",
      "\n",
      "\n",
      "Client 5 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.007467111693582571\n",
      "Epoch 2 loss: 0.004493099935312758\n",
      "Epoch 3 loss: 0.0002385201558311716\n",
      "Epoch 4 loss: 7.473603680732039e-05\n",
      "Epoch 5 loss: 6.010265741867547e-05\n",
      "Epoch 6 loss: 5.126266711310462e-05\n",
      "Epoch 7 loss: 4.542555123466158e-05\n",
      "Epoch 8 loss: 4.1086426133791244e-05\n",
      "Epoch 9 loss: 3.770212634588054e-05\n",
      "Epoch 10 loss: 3.474881345510994e-05\n",
      "Epoch 11 loss: 3.241526624134062e-05\n",
      "Epoch 12 loss: 3.060348836267556e-05\n",
      "Epoch 13 loss: 2.8797015169890194e-05\n",
      "Epoch 14 loss: 2.7295301471684963e-05\n",
      "Epoch 15 loss: 2.5896840579624065e-05\n",
      "Epoch 16 loss: 2.478041545999113e-05\n",
      "Epoch 17 loss: 2.3745944860133944e-05\n",
      "Epoch 18 loss: 2.2636050925436673e-05\n",
      "Epoch 19 loss: 2.2027597686626073e-05\n",
      "Epoch 20 loss: 2.094420842835996e-05\n",
      "Epoch 21 loss: 2.0255536126422562e-05\n",
      "Epoch 22 loss: 1.947523562568965e-05\n",
      "Epoch 23 loss: 1.8820763115309485e-05\n",
      "Epoch 24 loss: 1.819946996922554e-05\n",
      "Epoch 25 loss: 1.7613551478356137e-05\n",
      "Epoch 26 loss: 1.7105981784213738e-05\n",
      "Epoch 27 loss: 1.657225069651867e-05\n",
      "Epoch 28 loss: 1.608500855906146e-05\n",
      "Epoch 29 loss: 1.568093042024458e-05\n",
      "Epoch 30 loss: 1.528396343334325e-05\n",
      "\n",
      "Accuracy of the network: 98.93, Loss: 0.0\n",
      "Loss difference: 0.0\n",
      "Global Round 7 ends\n",
      "\n",
      "\n",
      " ====================== Global Round 9 ======================\n",
      "Client 1 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.009013375267389592\n",
      "Epoch 2 loss: 0.003198593273926639\n",
      "Epoch 3 loss: 0.000414964253278873\n",
      "Epoch 4 loss: 7.605272470670266e-05\n",
      "Epoch 5 loss: 4.540933750104524e-05\n",
      "Epoch 6 loss: 3.448493892845519e-05\n",
      "Epoch 7 loss: 3.0315298883345404e-05\n",
      "Epoch 8 loss: 2.742403599330102e-05\n",
      "Epoch 9 loss: 2.5787138351469098e-05\n",
      "Epoch 10 loss: 2.3429020257090675e-05\n",
      "Epoch 11 loss: 2.1975443674700134e-05\n",
      "Epoch 12 loss: 2.069319638220907e-05\n",
      "Epoch 13 loss: 1.9527065465447165e-05\n",
      "Epoch 14 loss: 1.856674171366094e-05\n",
      "Epoch 15 loss: 1.8019978176482218e-05\n",
      "Epoch 16 loss: 1.692249997224523e-05\n",
      "Epoch 17 loss: 1.631006840417877e-05\n",
      "Epoch 18 loss: 1.5570673038341583e-05\n",
      "Epoch 19 loss: 1.5202368357826722e-05\n",
      "Epoch 20 loss: 1.445864404381266e-05\n",
      "Epoch 21 loss: 1.3956293281076096e-05\n",
      "Epoch 22 loss: 1.3497500196942398e-05\n",
      "Epoch 23 loss: 1.3078755118391866e-05\n",
      "Epoch 24 loss: 1.2701803202569772e-05\n",
      "Epoch 25 loss: 1.2369920516160006e-05\n",
      "Epoch 26 loss: 1.2036070810418543e-05\n",
      "Epoch 27 loss: 1.1644826337492892e-05\n",
      "Epoch 28 loss: 1.1375459332321818e-05\n",
      "Epoch 29 loss: 1.1050175078248036e-05\n",
      "Epoch 30 loss: 1.0778727078710772e-05\n",
      "\n",
      "\n",
      "Client 2 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.0020897693258433597\n",
      "Epoch 2 loss: 0.005450477155784271\n",
      "Epoch 3 loss: 0.0047226422559079944\n",
      "Epoch 4 loss: 0.00034136791834832195\n",
      "Epoch 5 loss: 3.796669097900313e-05\n",
      "Epoch 6 loss: 2.582456165202802e-05\n",
      "Epoch 7 loss: 2.2471125112663995e-05\n",
      "Epoch 8 loss: 2.0322885413217844e-05\n",
      "Epoch 9 loss: 1.8652808154949198e-05\n",
      "Epoch 10 loss: 1.7341071019115443e-05\n",
      "Epoch 11 loss: 1.6211114580857824e-05\n",
      "Epoch 12 loss: 1.5344429825983194e-05\n",
      "Epoch 13 loss: 1.4533798052394643e-05\n",
      "Epoch 14 loss: 1.3856599529898573e-05\n",
      "Epoch 15 loss: 1.32331539433559e-05\n",
      "Epoch 16 loss: 1.269246572779648e-05\n",
      "Epoch 17 loss: 1.218233904014472e-05\n",
      "Epoch 18 loss: 1.1776289023620624e-05\n",
      "Epoch 19 loss: 1.1337500153769026e-05\n",
      "Epoch 20 loss: 1.099273804808468e-05\n",
      "Epoch 21 loss: 1.0616518628762802e-05\n",
      "Epoch 22 loss: 1.0299246943011804e-05\n",
      "Epoch 23 loss: 1.001753658625816e-05\n",
      "Epoch 24 loss: 9.733301986987376e-06\n",
      "Epoch 25 loss: 9.446126644826256e-06\n",
      "Epoch 26 loss: 9.254339493958861e-06\n",
      "Epoch 27 loss: 8.97748408257529e-06\n",
      "Epoch 28 loss: 8.766920990913444e-06\n",
      "Epoch 29 loss: 8.556357677646355e-06\n",
      "Epoch 30 loss: 8.357423354269106e-06\n",
      "\n",
      "\n",
      "Client 3 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.007580240659538487\n",
      "Epoch 2 loss: 0.004054708076106384\n",
      "Epoch 3 loss: 0.0003519867755756832\n",
      "Epoch 4 loss: 9.121828145895237e-05\n",
      "Epoch 5 loss: 3.7683594754261735e-05\n",
      "Epoch 6 loss: 3.214897613187644e-05\n",
      "Epoch 7 loss: 2.8504250688650807e-05\n",
      "Epoch 8 loss: 2.5802658876851724e-05\n",
      "Epoch 9 loss: 2.3740826988399974e-05\n",
      "Epoch 10 loss: 2.195541862064782e-05\n",
      "Epoch 11 loss: 2.0682067392035213e-05\n",
      "Epoch 12 loss: 1.9225284177417786e-05\n",
      "Epoch 13 loss: 1.8196279698567374e-05\n",
      "Epoch 14 loss: 1.7302351200284347e-05\n",
      "Epoch 15 loss: 1.6465973205048842e-05\n",
      "Epoch 16 loss: 1.5746641124087323e-05\n",
      "Epoch 17 loss: 1.5129690765558479e-05\n",
      "Epoch 18 loss: 1.451713395920183e-05\n",
      "Epoch 19 loss: 1.3974045189620889e-05\n",
      "Epoch 20 loss: 1.3683783088978564e-05\n",
      "Epoch 21 loss: 1.3016430075024503e-05\n",
      "Epoch 22 loss: 1.2588131739201246e-05\n",
      "Epoch 23 loss: 1.220138026558862e-05\n",
      "Epoch 24 loss: 1.204299159821541e-05\n",
      "Epoch 25 loss: 1.1501445583762608e-05\n",
      "Epoch 26 loss: 1.1333520289690659e-05\n",
      "Epoch 27 loss: 1.0891121143947582e-05\n",
      "Epoch 28 loss: 1.0617039713488998e-05\n",
      "Epoch 29 loss: 1.0354167597489912e-05\n",
      "Epoch 30 loss: 1.011394717652115e-05\n",
      "\n",
      "\n",
      "Client 4 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.008695563911430625\n",
      "Epoch 2 loss: 0.003344904617826037\n",
      "Epoch 3 loss: 0.002421745444561083\n",
      "Epoch 4 loss: 0.00044087652828243926\n",
      "Epoch 5 loss: 7.444462269153166e-05\n",
      "Epoch 6 loss: 5.175970162658536e-05\n",
      "Epoch 7 loss: 4.4097818341331495e-05\n",
      "Epoch 8 loss: 3.90800652545581e-05\n",
      "Epoch 9 loss: 3.525175120245459e-05\n",
      "Epoch 10 loss: 3.240853065255413e-05\n",
      "Epoch 11 loss: 3.0185193602541157e-05\n",
      "Epoch 12 loss: 2.791660127941059e-05\n",
      "Epoch 13 loss: 2.6234728295624437e-05\n",
      "Epoch 14 loss: 2.4664816239893532e-05\n",
      "Epoch 15 loss: 2.334665404616094e-05\n",
      "Epoch 16 loss: 2.221682486160617e-05\n",
      "Epoch 17 loss: 2.1200085250350694e-05\n",
      "Epoch 18 loss: 2.046194915155403e-05\n",
      "Epoch 19 loss: 1.9473504933315366e-05\n",
      "Epoch 20 loss: 1.8733473355076268e-05\n",
      "Epoch 21 loss: 1.813877747820208e-05\n",
      "Epoch 22 loss: 1.79108282242024e-05\n",
      "Epoch 23 loss: 1.68734424388456e-05\n",
      "Epoch 24 loss: 1.6259295457154752e-05\n",
      "Epoch 25 loss: 1.57993834466983e-05\n",
      "Epoch 26 loss: 1.526072540166466e-05\n",
      "Epoch 27 loss: 1.4902795932641162e-05\n",
      "Epoch 28 loss: 1.4460898756957573e-05\n",
      "Epoch 29 loss: 1.4063712759315255e-05\n",
      "Epoch 30 loss: 1.3749368480063499e-05\n",
      "\n",
      "\n",
      "Client 5 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.009769306258269196\n",
      "Epoch 2 loss: 0.001623438700346486\n",
      "Epoch 3 loss: 0.004398724327897001\n",
      "Epoch 4 loss: 0.001854220389915706\n",
      "Epoch 5 loss: 0.00018521077016089672\n",
      "Epoch 6 loss: 5.8803795766513854e-05\n",
      "Epoch 7 loss: 4.527784493566122e-05\n",
      "Epoch 8 loss: 3.8900330198565996e-05\n",
      "Epoch 9 loss: 3.494064209643143e-05\n",
      "Epoch 10 loss: 3.18111138355259e-05\n",
      "Epoch 11 loss: 2.942989640727627e-05\n",
      "Epoch 12 loss: 2.7290087412827713e-05\n",
      "Epoch 13 loss: 2.5624177472099168e-05\n",
      "Epoch 14 loss: 2.4409095798816338e-05\n",
      "Epoch 15 loss: 2.324144891597422e-05\n",
      "Epoch 16 loss: 2.1737788007979597e-05\n",
      "Epoch 17 loss: 2.0802875470625687e-05\n",
      "Epoch 18 loss: 1.9844060630288565e-05\n",
      "Epoch 19 loss: 1.9090517429741464e-05\n",
      "Epoch 20 loss: 1.8337590116374864e-05\n",
      "Epoch 21 loss: 1.7669590283134725e-05\n",
      "Epoch 22 loss: 1.713079250943746e-05\n",
      "Epoch 23 loss: 1.646526001668055e-05\n",
      "Epoch 24 loss: 1.5940912385251612e-05\n",
      "Epoch 25 loss: 1.5492532617092205e-05\n",
      "Epoch 26 loss: 1.5041240798812839e-05\n",
      "Epoch 27 loss: 1.4529059855944792e-05\n",
      "Epoch 28 loss: 1.415965250879817e-05\n",
      "Epoch 29 loss: 1.383347171366314e-05\n",
      "Epoch 30 loss: 1.3510993940798726e-05\n",
      "\n",
      "Accuracy of the network: 99.07, Loss: 0.0\n",
      "Loss difference: 0.0\n",
      "Global Round 8 ends\n",
      "\n",
      "\n",
      " ====================== Global Round 10 ======================\n",
      "Client 1 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.006133483382748279\n",
      "Epoch 2 loss: 0.001247218459282657\n",
      "Epoch 3 loss: 0.00013419585526275313\n",
      "Epoch 4 loss: 4.3313396979322255e-05\n",
      "Epoch 5 loss: 3.292208906333024e-05\n",
      "Epoch 6 loss: 2.8326736961913982e-05\n",
      "Epoch 7 loss: 2.5421931118824536e-05\n",
      "Epoch 8 loss: 2.3247141352139686e-05\n",
      "Epoch 9 loss: 2.151422010727604e-05\n",
      "Epoch 10 loss: 2.0263812125684938e-05\n",
      "Epoch 11 loss: 1.889362954441751e-05\n",
      "Epoch 12 loss: 1.7801835241090153e-05\n",
      "Epoch 13 loss: 1.689648671264447e-05\n",
      "Epoch 14 loss: 1.6265814537319332e-05\n",
      "Epoch 15 loss: 1.5372542988117137e-05\n",
      "Epoch 16 loss: 1.484394042084128e-05\n",
      "Epoch 17 loss: 1.4246967287744257e-05\n",
      "Epoch 18 loss: 1.3644551798748546e-05\n",
      "Epoch 19 loss: 1.3172814085630888e-05\n",
      "Epoch 20 loss: 1.2699278386953147e-05\n",
      "Epoch 21 loss: 1.2316103785458164e-05\n",
      "Epoch 22 loss: 1.1926098196633022e-05\n",
      "Epoch 23 loss: 1.1561393584638053e-05\n",
      "Epoch 24 loss: 1.1248555545844897e-05\n",
      "Epoch 25 loss: 1.098149755951697e-05\n",
      "Epoch 26 loss: 1.0662521133035595e-05\n",
      "Epoch 27 loss: 1.0397482850940133e-05\n",
      "Epoch 28 loss: 1.0182914738871362e-05\n",
      "Epoch 29 loss: 9.916404347460836e-06\n",
      "Epoch 30 loss: 9.655109189157382e-06\n",
      "\n",
      "\n",
      "Client 2 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.002609947829357656\n",
      "Epoch 2 loss: 0.00399207613375251\n",
      "Epoch 3 loss: 0.003053612427084665\n",
      "Epoch 4 loss: 0.0012283592880248727\n",
      "Epoch 5 loss: 0.0012440117959321075\n",
      "Epoch 6 loss: 2.3274964084609858e-05\n",
      "Epoch 7 loss: 1.6319822289261368e-05\n",
      "Epoch 8 loss: 1.3760514725152348e-05\n",
      "Epoch 9 loss: 1.239842863634721e-05\n",
      "Epoch 10 loss: 1.143469351605475e-05\n",
      "Epoch 11 loss: 1.050626845556861e-05\n",
      "Epoch 12 loss: 9.865698005747919e-06\n",
      "Epoch 13 loss: 9.333571748941003e-06\n",
      "Epoch 14 loss: 8.890101764668964e-06\n",
      "Epoch 15 loss: 8.485184174613068e-06\n",
      "Epoch 16 loss: 8.138578441131015e-06\n",
      "Epoch 17 loss: 7.836585651509394e-06\n",
      "Epoch 18 loss: 7.563998461621921e-06\n",
      "Epoch 19 loss: 7.3119215868887514e-06\n",
      "Epoch 20 loss: 7.170288602272891e-06\n",
      "Epoch 21 loss: 6.875311716646743e-06\n",
      "Epoch 22 loss: 6.687128246782481e-06\n",
      "Epoch 23 loss: 6.5458779877766896e-06\n",
      "Epoch 24 loss: 6.372318235614926e-06\n",
      "Epoch 25 loss: 6.181947094568158e-06\n",
      "Epoch 26 loss: 6.040505167345608e-06\n",
      "Epoch 27 loss: 5.911731547089151e-06\n",
      "Epoch 28 loss: 5.798521698070799e-06\n",
      "Epoch 29 loss: 5.667750647816344e-06\n",
      "Epoch 30 loss: 5.602070971729026e-06\n",
      "\n",
      "\n",
      "Client 3 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.0039647824076784735\n",
      "Epoch 2 loss: 0.004382698018787777\n",
      "Epoch 3 loss: 0.0009193558323833702\n",
      "Epoch 4 loss: 4.684884008950864e-05\n",
      "Epoch 5 loss: 3.1313620767092294e-05\n",
      "Epoch 6 loss: 2.7029803707831893e-05\n",
      "Epoch 7 loss: 2.4157733309580735e-05\n",
      "Epoch 8 loss: 2.195933297330779e-05\n",
      "Epoch 9 loss: 2.026206169904915e-05\n",
      "Epoch 10 loss: 1.8859057870534516e-05\n",
      "Epoch 11 loss: 1.7682299527817396e-05\n",
      "Epoch 12 loss: 1.6667765788127705e-05\n",
      "Epoch 13 loss: 1.5821364214098384e-05\n",
      "Epoch 14 loss: 1.5031334809365676e-05\n",
      "Epoch 15 loss: 1.4379235773008034e-05\n",
      "Epoch 16 loss: 1.3788212548075278e-05\n",
      "Epoch 17 loss: 1.3241007484990884e-05\n",
      "Epoch 18 loss: 1.2744707844893922e-05\n",
      "Epoch 19 loss: 1.2303359437931698e-05\n",
      "Epoch 20 loss: 1.1877996711211764e-05\n",
      "Epoch 21 loss: 1.1503315537070645e-05\n",
      "Epoch 22 loss: 1.1242121949390263e-05\n",
      "Epoch 23 loss: 1.0938408950166809e-05\n",
      "Epoch 24 loss: 1.0526334138404952e-05\n",
      "Epoch 25 loss: 1.0224050170166652e-05\n",
      "Epoch 26 loss: 9.97181166356779e-06\n",
      "Epoch 27 loss: 9.688432309582354e-06\n",
      "Epoch 28 loss: 9.488362467729757e-06\n",
      "Epoch 29 loss: 9.248662583546657e-06\n",
      "Epoch 30 loss: 9.156069350718548e-06\n",
      "\n",
      "\n",
      "Client 4 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.008901905752555053\n",
      "Epoch 2 loss: 0.002397956074766379\n",
      "Epoch 3 loss: 0.0008012315843389534\n",
      "Epoch 4 loss: 9.51117151810243e-05\n",
      "Epoch 5 loss: 5.901404274792721e-05\n",
      "Epoch 6 loss: 4.9945768259423394e-05\n",
      "Epoch 7 loss: 4.3656166796492176e-05\n",
      "Epoch 8 loss: 3.904159357373833e-05\n",
      "Epoch 9 loss: 3.573411572828042e-05\n",
      "Epoch 10 loss: 3.306635276534534e-05\n",
      "Epoch 11 loss: 3.100346040095484e-05\n",
      "Epoch 12 loss: 2.9007109392176685e-05\n",
      "Epoch 13 loss: 2.7190294603530328e-05\n",
      "Epoch 14 loss: 2.6082159372039764e-05\n",
      "Epoch 15 loss: 2.4557482269664622e-05\n",
      "Epoch 16 loss: 2.35338892485577e-05\n",
      "Epoch 17 loss: 2.2517977047234166e-05\n",
      "Epoch 18 loss: 2.1792679619538334e-05\n",
      "Epoch 19 loss: 2.0678197460799228e-05\n",
      "Epoch 20 loss: 1.99209723177849e-05\n",
      "Epoch 21 loss: 1.932035836345e-05\n",
      "Epoch 22 loss: 1.8570841193116604e-05\n",
      "Epoch 23 loss: 1.7966621435082345e-05\n",
      "Epoch 24 loss: 1.739820971387927e-05\n",
      "Epoch 25 loss: 1.6900790879114515e-05\n",
      "Epoch 26 loss: 1.6408844815607213e-05\n",
      "Epoch 27 loss: 1.5894532945855044e-05\n",
      "Epoch 28 loss: 1.5506221987079665e-05\n",
      "Epoch 29 loss: 1.5171674106475716e-05\n",
      "Epoch 30 loss: 1.4680510100687234e-05\n",
      "\n",
      "\n",
      "Client 5 dropped\n",
      "Accuracy of the network: 99.0, Loss: 0.0\n",
      "Loss difference: 0.0\n",
      "Global Round 9 ends\n",
      "\n",
      "\n",
      " ====================== Global Round 11 ======================\n",
      "Client 1 dropped\n",
      "Client 2 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.0010943462657444928\n",
      "Epoch 2 loss: 0.0004344186021702105\n",
      "Epoch 3 loss: 0.0007409851762933766\n",
      "Epoch 4 loss: 0.00016556933048082666\n",
      "Epoch 5 loss: 2.979487688540496e-05\n",
      "Epoch 6 loss: 2.19339180422167e-05\n",
      "Epoch 7 loss: 1.8939284000774757e-05\n",
      "Epoch 8 loss: 1.699683364708479e-05\n",
      "Epoch 9 loss: 1.5553936513485266e-05\n",
      "Epoch 10 loss: 1.4458314052474033e-05\n",
      "Epoch 11 loss: 1.3693320856802322e-05\n",
      "Epoch 12 loss: 1.2732901169883329e-05\n",
      "Epoch 13 loss: 1.2058368901282232e-05\n",
      "Epoch 14 loss: 1.1465203743923725e-05\n",
      "Epoch 15 loss: 1.0983122368869637e-05\n",
      "Epoch 16 loss: 1.0470249369221502e-05\n",
      "Epoch 17 loss: 1.0056614135673771e-05\n",
      "Epoch 18 loss: 9.759009376501196e-06\n",
      "Epoch 19 loss: 9.320057594083181e-06\n",
      "Epoch 20 loss: 9.00002314293511e-06\n",
      "Epoch 21 loss: 8.771255586599964e-06\n",
      "Epoch 22 loss: 8.43354661702919e-06\n",
      "Epoch 23 loss: 8.174400935114576e-06\n",
      "Epoch 24 loss: 7.94834311486152e-06\n",
      "Epoch 25 loss: 7.712018664888928e-06\n",
      "Epoch 26 loss: 7.5179347378019655e-06\n",
      "Epoch 27 loss: 7.32471019649976e-06\n",
      "Epoch 28 loss: 7.205599486193628e-06\n",
      "Epoch 29 loss: 6.953434987875357e-06\n",
      "Epoch 30 loss: 6.87824165311808e-06\n",
      "\n",
      "\n",
      "Client 3 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.004291486158621391\n",
      "Epoch 2 loss: 0.0011398119722452194\n",
      "Epoch 3 loss: 0.0002724592801180815\n",
      "Epoch 4 loss: 2.8019426898172534e-05\n",
      "Epoch 5 loss: 2.1244636936950633e-05\n",
      "Epoch 6 loss: 1.8535212954912945e-05\n",
      "Epoch 7 loss: 1.6630123255443424e-05\n",
      "Epoch 8 loss: 1.520635184827675e-05\n",
      "Epoch 9 loss: 1.4157904151160427e-05\n",
      "Epoch 10 loss: 1.322460900988647e-05\n",
      "Epoch 11 loss: 1.2471280323664705e-05\n",
      "Epoch 12 loss: 1.1794844211788496e-05\n",
      "Epoch 13 loss: 1.1228448818175538e-05\n",
      "Epoch 14 loss: 1.0725180787570339e-05\n",
      "Epoch 15 loss: 1.0240880762269868e-05\n",
      "Epoch 16 loss: 9.836528091780771e-06\n",
      "Epoch 17 loss: 9.504389506691689e-06\n",
      "Epoch 18 loss: 9.109810393247832e-06\n",
      "Epoch 19 loss: 8.801471307711895e-06\n",
      "Epoch 20 loss: 8.5465175448999e-06\n",
      "Epoch 21 loss: 8.250532330537051e-06\n",
      "Epoch 22 loss: 7.996913990187975e-06\n",
      "Epoch 23 loss: 7.763169315809474e-06\n",
      "Epoch 24 loss: 7.5568228552610494e-06\n",
      "Epoch 25 loss: 7.351806419114113e-06\n",
      "Epoch 26 loss: 7.166234263358651e-06\n",
      "Epoch 27 loss: 6.998287026920929e-06\n",
      "Epoch 28 loss: 6.8266210225773e-06\n",
      "Epoch 29 loss: 6.657980226463576e-06\n",
      "Epoch 30 loss: 6.508574053279721e-06\n",
      "\n",
      "\n",
      "Client 4 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.010654415635478925\n",
      "Epoch 2 loss: 0.0037648401355741697\n",
      "Epoch 3 loss: 0.0017254866241937258\n",
      "Epoch 4 loss: 0.000368503833726172\n",
      "Epoch 5 loss: 6.928164221354852e-05\n",
      "Epoch 6 loss: 1.735594151451787e-05\n",
      "Epoch 7 loss: 1.583697437878408e-05\n",
      "Epoch 8 loss: 1.4695684759006737e-05\n",
      "Epoch 9 loss: 1.3788259796682196e-05\n",
      "Epoch 10 loss: 1.306894098824501e-05\n",
      "Epoch 11 loss: 1.2524113998385954e-05\n",
      "Epoch 12 loss: 1.195559187950252e-05\n",
      "Epoch 13 loss: 1.161252240429367e-05\n",
      "Epoch 14 loss: 1.1146055234523515e-05\n",
      "Epoch 15 loss: 1.0662168864332027e-05\n",
      "Epoch 16 loss: 1.0328427543085206e-05\n",
      "Epoch 17 loss: 9.990941870988914e-06\n",
      "Epoch 18 loss: 9.720670043075692e-06\n",
      "Epoch 19 loss: 9.445502957703033e-06\n",
      "Epoch 20 loss: 9.220336184589713e-06\n",
      "Epoch 21 loss: 8.982767188444147e-06\n",
      "Epoch 22 loss: 8.811287337360583e-06\n",
      "Epoch 23 loss: 8.591392667100835e-06\n",
      "Epoch 24 loss: 8.609193408815407e-06\n",
      "Epoch 25 loss: 8.1935215090254e-06\n",
      "Epoch 26 loss: 8.0135242402428e-06\n",
      "Epoch 27 loss: 7.849635916672236e-06\n",
      "Epoch 28 loss: 7.709602865441916e-06\n",
      "Epoch 29 loss: 7.558191057256012e-06\n",
      "Epoch 30 loss: 7.423662007197779e-06\n",
      "\n",
      "\n",
      "Client 5 dropped\n",
      "Accuracy of the network: 99.13, Loss: 0.0\n",
      "Loss difference: 0.0\n",
      "Global Round 10 ends\n",
      "\n",
      "\n",
      " ====================== Global Round 12 ======================\n",
      "Client 1 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.010502429412432263\n",
      "Epoch 2 loss: 0.0021183606367020055\n",
      "Epoch 3 loss: 0.0016918573924703452\n",
      "Epoch 4 loss: 0.0001227081776292692\n",
      "Epoch 5 loss: 3.9741352024633786e-05\n",
      "Epoch 6 loss: 3.084054825805368e-05\n",
      "Epoch 7 loss: 2.6599810227033893e-05\n",
      "Epoch 8 loss: 2.4112628936898315e-05\n",
      "Epoch 9 loss: 2.1840500887058702e-05\n",
      "Epoch 10 loss: 2.093341879436047e-05\n",
      "Epoch 11 loss: 1.9299662598943608e-05\n",
      "Epoch 12 loss: 1.780661313503175e-05\n",
      "Epoch 13 loss: 1.6873878223206915e-05\n",
      "Epoch 14 loss: 1.6029410492161684e-05\n",
      "Epoch 15 loss: 1.53815356881533e-05\n",
      "Epoch 16 loss: 1.468178577226211e-05\n",
      "Epoch 17 loss: 1.4204308385600674e-05\n",
      "Epoch 18 loss: 1.3603125952547776e-05\n",
      "Epoch 19 loss: 1.3082549421209432e-05\n",
      "Epoch 20 loss: 1.26525720854967e-05\n",
      "Epoch 21 loss: 1.2266660161285705e-05\n",
      "Epoch 22 loss: 1.1854296621550285e-05\n",
      "Epoch 23 loss: 1.152627784963916e-05\n",
      "Epoch 24 loss: 1.1316733200050305e-05\n",
      "Epoch 25 loss: 1.0857422105459973e-05\n",
      "Epoch 26 loss: 1.0590943848166328e-05\n",
      "Epoch 27 loss: 1.0298299741720407e-05\n",
      "Epoch 28 loss: 1.0024741805563515e-05\n",
      "Epoch 29 loss: 9.787401443006368e-06\n",
      "Epoch 30 loss: 9.643172248179745e-06\n",
      "\n",
      "\n",
      "Client 2 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.008770259163203177\n",
      "Epoch 2 loss: 0.002404566698797101\n",
      "Epoch 3 loss: 0.0007466257357619249\n",
      "Epoch 4 loss: 5.370472534442122e-05\n",
      "Epoch 5 loss: 2.2639185004331426e-05\n",
      "Epoch 6 loss: 1.9457465743705335e-05\n",
      "Epoch 7 loss: 1.7472372290718993e-05\n",
      "Epoch 8 loss: 1.5865232289327504e-05\n",
      "Epoch 9 loss: 1.4747709848444152e-05\n",
      "Epoch 10 loss: 1.3769280529828445e-05\n",
      "Epoch 11 loss: 1.2851644699202309e-05\n",
      "Epoch 12 loss: 1.2180870097447925e-05\n",
      "Epoch 13 loss: 1.152977802809061e-05\n",
      "Epoch 14 loss: 1.1048297354356177e-05\n",
      "Epoch 15 loss: 1.0522440633281443e-05\n",
      "Epoch 16 loss: 1.0091154826087427e-05\n",
      "Epoch 17 loss: 9.697200765314538e-06\n",
      "Epoch 18 loss: 9.332103732411742e-06\n",
      "Epoch 19 loss: 9.0083926949068e-06\n",
      "Epoch 20 loss: 8.719276002535069e-06\n",
      "Epoch 21 loss: 8.440845837294634e-06\n",
      "Epoch 22 loss: 8.19483544363545e-06\n",
      "Epoch 23 loss: 7.939806082425936e-06\n",
      "Epoch 24 loss: 7.882304141277601e-06\n",
      "Epoch 25 loss: 7.542330306077269e-06\n",
      "Epoch 26 loss: 7.320030559948565e-06\n",
      "Epoch 27 loss: 7.141905912023399e-06\n",
      "Epoch 28 loss: 6.96367106174449e-06\n",
      "Epoch 29 loss: 6.827689999900036e-06\n",
      "Epoch 30 loss: 6.643798134323438e-06\n",
      "\n",
      "\n",
      "Client 3 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.005013774003856705\n",
      "Epoch 2 loss: 0.002280717199244055\n",
      "Epoch 3 loss: 0.0006460255055605785\n",
      "Epoch 4 loss: 0.0007759032857322231\n",
      "Epoch 5 loss: 0.0016078176539380971\n",
      "Epoch 6 loss: 0.00013745897608910776\n",
      "Epoch 7 loss: 3.0943804486635286e-05\n",
      "Epoch 8 loss: 2.5215126906462117e-05\n",
      "Epoch 9 loss: 2.1841329517388537e-05\n",
      "Epoch 10 loss: 1.9626879913265902e-05\n",
      "Epoch 11 loss: 1.7914826614492657e-05\n",
      "Epoch 12 loss: 1.6527641462679296e-05\n",
      "Epoch 13 loss: 1.5475063114287454e-05\n",
      "Epoch 14 loss: 1.4522824582590416e-05\n",
      "Epoch 15 loss: 1.3746278216497771e-05\n",
      "Epoch 16 loss: 1.304520691965039e-05\n",
      "Epoch 17 loss: 1.267072483569746e-05\n",
      "Epoch 18 loss: 1.1925139208694317e-05\n",
      "Epoch 19 loss: 1.1410602280809263e-05\n",
      "Epoch 20 loss: 1.0973852282721167e-05\n",
      "Epoch 21 loss: 1.0587199986114393e-05\n",
      "Epoch 22 loss: 1.0218294988805031e-05\n",
      "Epoch 23 loss: 9.887916081157535e-06\n",
      "Epoch 24 loss: 9.582283439754824e-06\n",
      "Epoch 25 loss: 9.331364071444517e-06\n",
      "Epoch 26 loss: 9.035089934210224e-06\n",
      "Epoch 27 loss: 8.765645789872346e-06\n",
      "Epoch 28 loss: 8.619829726474778e-06\n",
      "Epoch 29 loss: 8.334563194154346e-06\n",
      "Epoch 30 loss: 8.109689596997352e-06\n",
      "\n",
      "\n",
      "Client 4 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.004410394489126364\n",
      "Epoch 2 loss: 0.005031255924614638\n",
      "Epoch 3 loss: 0.00030065342346865674\n",
      "Epoch 4 loss: 4.12353757002097e-05\n",
      "Epoch 5 loss: 3.230763251396293e-05\n",
      "Epoch 6 loss: 2.753852659445197e-05\n",
      "Epoch 7 loss: 2.4275721822241773e-05\n",
      "Epoch 8 loss: 2.223018800761908e-05\n",
      "Epoch 9 loss: 2.0015067812811807e-05\n",
      "Epoch 10 loss: 1.8453439695184353e-05\n",
      "Epoch 11 loss: 1.7256540351869405e-05\n",
      "Epoch 12 loss: 1.619370650387436e-05\n",
      "Epoch 13 loss: 1.5344596014417366e-05\n",
      "Epoch 14 loss: 1.4522131112417877e-05\n",
      "Epoch 15 loss: 1.381753726724359e-05\n",
      "Epoch 16 loss: 1.3190881652755925e-05\n",
      "Epoch 17 loss: 1.2655019323559015e-05\n",
      "Epoch 18 loss: 1.215508489668848e-05\n",
      "Epoch 19 loss: 1.172926978732538e-05\n",
      "Epoch 20 loss: 1.1300024683657149e-05\n",
      "Epoch 21 loss: 1.0936910998485084e-05\n",
      "Epoch 22 loss: 1.0589827181913365e-05\n",
      "Epoch 23 loss: 1.0282009799474226e-05\n",
      "Epoch 24 loss: 9.996983723021777e-06\n",
      "Epoch 25 loss: 9.761696981125861e-06\n",
      "Epoch 26 loss: 9.479526083158895e-06\n",
      "Epoch 27 loss: 9.194226671378079e-06\n",
      "Epoch 28 loss: 8.980035994899773e-06\n",
      "Epoch 29 loss: 8.766545137438032e-06\n",
      "Epoch 30 loss: 8.556067616703006e-06\n",
      "\n",
      "\n",
      "Client 5 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.019492031803960048\n",
      "Epoch 2 loss: 0.009957715017065237\n",
      "Epoch 3 loss: 0.002439105323732591\n",
      "Epoch 4 loss: 0.0002277724041291966\n",
      "Epoch 5 loss: 6.315761670824284e-05\n",
      "Epoch 6 loss: 5.111674470837297e-05\n",
      "Epoch 7 loss: 4.367646460152705e-05\n",
      "Epoch 8 loss: 3.910598155260188e-05\n",
      "Epoch 9 loss: 3.542049386520046e-05\n",
      "Epoch 10 loss: 3.257408276919373e-05\n",
      "Epoch 11 loss: 3.042338262178224e-05\n",
      "Epoch 12 loss: 2.8263596872841933e-05\n",
      "Epoch 13 loss: 2.656782770731856e-05\n",
      "Epoch 14 loss: 2.5089501559282882e-05\n",
      "Epoch 15 loss: 2.3853060510831965e-05\n",
      "Epoch 16 loss: 2.2728194816970112e-05\n",
      "Epoch 17 loss: 2.2064742510026402e-05\n",
      "Epoch 18 loss: 2.086976476701114e-05\n",
      "Epoch 19 loss: 1.9936988253050855e-05\n",
      "Epoch 20 loss: 1.9193848964540602e-05\n",
      "Epoch 21 loss: 1.84457322044347e-05\n",
      "Epoch 22 loss: 1.7782574505198016e-05\n",
      "Epoch 23 loss: 1.725823987936686e-05\n",
      "Epoch 24 loss: 1.66350093038698e-05\n",
      "Epoch 25 loss: 1.6099485534605346e-05\n",
      "Epoch 26 loss: 1.5624728764832302e-05\n",
      "Epoch 27 loss: 1.5173153359559806e-05\n",
      "Epoch 28 loss: 1.475995512386192e-05\n",
      "Epoch 29 loss: 1.4367579318445225e-05\n",
      "Epoch 30 loss: 1.4016636611040153e-05\n",
      "\n",
      "Accuracy of the network: 99.05, Loss: 0.0\n",
      "Loss difference: 0.0\n",
      "Global Round 11 ends\n",
      "\n",
      "\n",
      " ====================== Global Round 13 ======================\n",
      "Client 1 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.0038197992635915267\n",
      "Epoch 2 loss: 0.0016927372868578516\n",
      "Epoch 3 loss: 0.0001868395704010362\n",
      "Epoch 4 loss: 8.221180745653886e-05\n",
      "Epoch 5 loss: 2.9968534388054686e-05\n",
      "Epoch 6 loss: 2.5639471131894012e-05\n",
      "Epoch 7 loss: 2.251445073071701e-05\n",
      "Epoch 8 loss: 2.062959522848012e-05\n",
      "Epoch 9 loss: 1.9071067499715565e-05\n",
      "Epoch 10 loss: 1.7691318412676187e-05\n",
      "Epoch 11 loss: 1.6604515218409747e-05\n",
      "Epoch 12 loss: 1.5852007954985967e-05\n",
      "Epoch 13 loss: 1.483931710658266e-05\n",
      "Epoch 14 loss: 1.4143256550623093e-05\n",
      "Epoch 15 loss: 1.3543677465924397e-05\n",
      "Epoch 16 loss: 1.3078897418606032e-05\n",
      "Epoch 17 loss: 1.252741423155308e-05\n",
      "Epoch 18 loss: 1.2011844959592553e-05\n",
      "Epoch 19 loss: 1.1575055070032534e-05\n",
      "Epoch 20 loss: 1.120105920294838e-05\n",
      "Epoch 21 loss: 1.0850062025979108e-05\n",
      "Epoch 22 loss: 1.051201754062769e-05\n",
      "Epoch 23 loss: 1.0199800106534553e-05\n",
      "Epoch 24 loss: 9.93340699417102e-06\n",
      "Epoch 25 loss: 9.720878842209705e-06\n",
      "Epoch 26 loss: 9.406637034953376e-06\n",
      "Epoch 27 loss: 9.181329615201513e-06\n",
      "Epoch 28 loss: 8.948477279140907e-06\n",
      "Epoch 29 loss: 8.741988357406019e-06\n",
      "Epoch 30 loss: 8.550053749117054e-06\n",
      "\n",
      "\n",
      "Client 2 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.0025465884505728024\n",
      "Epoch 2 loss: 0.0025033993861820853\n",
      "Epoch 3 loss: 0.002762991647080253\n",
      "Epoch 4 loss: 4.876096391854539e-05\n",
      "Epoch 5 loss: 2.5403240144148738e-05\n",
      "Epoch 6 loss: 2.1096768727533756e-05\n",
      "Epoch 7 loss: 1.85292401052371e-05\n",
      "Epoch 8 loss: 1.6802949316656768e-05\n",
      "Epoch 9 loss: 1.5372948583442194e-05\n",
      "Epoch 10 loss: 1.4271146124986322e-05\n",
      "Epoch 11 loss: 1.3411191359811973e-05\n",
      "Epoch 12 loss: 1.2809608114539963e-05\n",
      "Epoch 13 loss: 1.2200966238863189e-05\n",
      "Epoch 14 loss: 1.1385393211069777e-05\n",
      "Epoch 15 loss: 1.0877282048506452e-05\n",
      "Epoch 16 loss: 1.0432224202971136e-05\n",
      "Epoch 17 loss: 1.0032005009831447e-05\n",
      "Epoch 18 loss: 9.883018357924058e-06\n",
      "Epoch 19 loss: 9.337324448561322e-06\n",
      "Epoch 20 loss: 9.077019965156367e-06\n",
      "Epoch 21 loss: 8.762402062959977e-06\n",
      "Epoch 22 loss: 8.482909381099938e-06\n",
      "Epoch 23 loss: 8.234734398782321e-06\n",
      "Epoch 24 loss: 8.008842848469161e-06\n",
      "Epoch 25 loss: 7.803305751669925e-06\n",
      "Epoch 26 loss: 7.61114681809212e-06\n",
      "Epoch 27 loss: 7.428742301295121e-06\n",
      "Epoch 28 loss: 7.297199877003917e-06\n",
      "Epoch 29 loss: 7.083542045239589e-06\n",
      "Epoch 30 loss: 6.926125414888764e-06\n",
      "\n",
      "\n",
      "Client 3 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.002627031085182285\n",
      "Epoch 2 loss: 0.002296659451527867\n",
      "Epoch 3 loss: 0.0009528443010876199\n",
      "Epoch 4 loss: 7.652226910952925e-05\n",
      "Epoch 5 loss: 2.4831068011224883e-05\n",
      "Epoch 6 loss: 2.083393508143097e-05\n",
      "Epoch 7 loss: 1.857063728881418e-05\n",
      "Epoch 8 loss: 1.6969420192767353e-05\n",
      "Epoch 9 loss: 1.5706927572965328e-05\n",
      "Epoch 10 loss: 1.4745362913316234e-05\n",
      "Epoch 11 loss: 1.3878705210408065e-05\n",
      "Epoch 12 loss: 1.3213102950369958e-05\n",
      "Epoch 13 loss: 1.2565961229475291e-05\n",
      "Epoch 14 loss: 1.217521347800557e-05\n",
      "Epoch 15 loss: 1.1561357161468606e-05\n",
      "Epoch 16 loss: 1.110707458756382e-05\n",
      "Epoch 17 loss: 1.0880747217594291e-05\n",
      "Epoch 18 loss: 1.0364665136322201e-05\n",
      "Epoch 19 loss: 1.002883157086948e-05\n",
      "Epoch 20 loss: 9.731013200163006e-06\n",
      "Epoch 21 loss: 9.477536218219998e-06\n",
      "Epoch 22 loss: 9.200269764867644e-06\n",
      "Epoch 23 loss: 8.959143893832302e-06\n",
      "Epoch 24 loss: 8.878918675658583e-06\n",
      "Epoch 25 loss: 8.513598042297899e-06\n",
      "Epoch 26 loss: 8.314957234776479e-06\n",
      "Epoch 27 loss: 8.117990490019948e-06\n",
      "Epoch 28 loss: 7.943226771700325e-06\n",
      "Epoch 29 loss: 7.778683488316428e-06\n",
      "Epoch 30 loss: 7.617413967510341e-06\n",
      "\n",
      "\n",
      "Client 4 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.0036939043370684613\n",
      "Epoch 2 loss: 0.0018199225809931623\n",
      "Epoch 3 loss: 0.00013807329549885686\n",
      "Epoch 4 loss: 3.858935360312218e-05\n",
      "Epoch 5 loss: 2.9794640415303775e-05\n",
      "Epoch 6 loss: 2.5861156767283506e-05\n",
      "Epoch 7 loss: 2.29059992064514e-05\n",
      "Epoch 8 loss: 2.0816898092108106e-05\n",
      "Epoch 9 loss: 1.9237009407032444e-05\n",
      "Epoch 10 loss: 1.8052227836686948e-05\n",
      "Epoch 11 loss: 1.6853999038905865e-05\n",
      "Epoch 12 loss: 1.5964076747369207e-05\n",
      "Epoch 13 loss: 1.516536299151884e-05\n",
      "Epoch 14 loss: 1.4506070184652835e-05\n",
      "Epoch 15 loss: 1.3842453895587508e-05\n",
      "Epoch 16 loss: 1.3326764200681725e-05\n",
      "Epoch 17 loss: 1.2820201233932857e-05\n",
      "Epoch 18 loss: 1.2389872322211275e-05\n",
      "Epoch 19 loss: 1.1952173784884298e-05\n",
      "Epoch 20 loss: 1.1535036382430035e-05\n",
      "Epoch 21 loss: 1.1224885049121447e-05\n",
      "Epoch 22 loss: 1.093707403049378e-05\n",
      "Epoch 23 loss: 1.058905246918559e-05\n",
      "Epoch 24 loss: 1.0302880269682064e-05\n",
      "Epoch 25 loss: 1.0070952106672784e-05\n",
      "Epoch 26 loss: 9.787784776227326e-06\n",
      "Epoch 27 loss: 9.556673397725686e-06\n",
      "Epoch 28 loss: 9.333392962986285e-06\n",
      "Epoch 29 loss: 9.1323108612945e-06\n",
      "Epoch 30 loss: 9.009578936038128e-06\n",
      "\n",
      "\n",
      "Client 5 dropped\n",
      "Accuracy of the network: 99.08, Loss: 0.0\n",
      "Loss difference: 0.0\n",
      "Global Round 12 ends\n",
      "\n",
      "\n",
      " ====================== Global Round 14 ======================\n",
      "Client 1 dropped\n",
      "Client 2 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.0015504779590402437\n",
      "Epoch 2 loss: 0.002647820940214077\n",
      "Epoch 3 loss: 4.701866696949769e-05\n",
      "Epoch 4 loss: 2.3510140075494576e-05\n",
      "Epoch 5 loss: 1.933195833663e-05\n",
      "Epoch 6 loss: 1.6930791683532077e-05\n",
      "Epoch 7 loss: 1.5165730430038166e-05\n",
      "Epoch 8 loss: 1.3886176590787688e-05\n",
      "Epoch 9 loss: 1.2874656016777143e-05\n",
      "Epoch 10 loss: 1.203429488607479e-05\n",
      "Epoch 11 loss: 1.1372547207310233e-05\n",
      "Epoch 12 loss: 1.0767869245059089e-05\n",
      "Epoch 13 loss: 1.0211156849780132e-05\n",
      "Epoch 14 loss: 9.801552863525236e-06\n",
      "Epoch 15 loss: 9.306198145553452e-06\n",
      "Epoch 16 loss: 8.935346730679733e-06\n",
      "Epoch 17 loss: 8.5959355643448e-06\n",
      "Epoch 18 loss: 8.282782046085218e-06\n",
      "Epoch 19 loss: 8.005339016848926e-06\n",
      "Epoch 20 loss: 7.871716065114724e-06\n",
      "Epoch 21 loss: 7.4857092602850015e-06\n",
      "Epoch 22 loss: 7.293632496806526e-06\n",
      "Epoch 23 loss: 7.065277662646964e-06\n",
      "Epoch 24 loss: 6.855096090452436e-06\n",
      "Epoch 25 loss: 6.673574749983606e-06\n",
      "Epoch 26 loss: 6.502570173002621e-06\n",
      "Epoch 27 loss: 6.347007375141205e-06\n",
      "Epoch 28 loss: 6.19442811216584e-06\n",
      "Epoch 29 loss: 6.0422077111891036e-06\n",
      "Epoch 30 loss: 5.909696433186103e-06\n",
      "\n",
      "\n",
      "Client 3 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.0005088163913364556\n",
      "Epoch 2 loss: 3.963172925141259e-05\n",
      "Epoch 3 loss: 2.3206619254615283e-05\n",
      "Epoch 4 loss: 1.941050554584912e-05\n",
      "Epoch 5 loss: 1.7232543692500008e-05\n",
      "Epoch 6 loss: 1.538985821761558e-05\n",
      "Epoch 7 loss: 1.412504913268155e-05\n",
      "Epoch 8 loss: 1.3104802662197535e-05\n",
      "Epoch 9 loss: 1.2387364440675266e-05\n",
      "Epoch 10 loss: 1.1581817421677497e-05\n",
      "Epoch 11 loss: 1.0946342252600231e-05\n",
      "Epoch 12 loss: 1.0431957821480393e-05\n",
      "Epoch 13 loss: 9.952712157586871e-06\n",
      "Epoch 14 loss: 9.57304844194698e-06\n",
      "Epoch 15 loss: 9.169581641221364e-06\n",
      "Epoch 16 loss: 8.843542869282137e-06\n",
      "Epoch 17 loss: 8.534868800056477e-06\n",
      "Epoch 18 loss: 8.26062727622612e-06\n",
      "Epoch 19 loss: 8.005091376093507e-06\n",
      "Epoch 20 loss: 7.76465124027205e-06\n",
      "Epoch 21 loss: 7.754546151379918e-06\n",
      "Epoch 22 loss: 7.35381896540508e-06\n",
      "Epoch 23 loss: 7.14601375925303e-06\n",
      "Epoch 24 loss: 6.966152306652608e-06\n",
      "Epoch 25 loss: 6.798082284524878e-06\n",
      "Epoch 26 loss: 6.647281248837745e-06\n",
      "Epoch 27 loss: 6.493302712329049e-06\n",
      "Epoch 28 loss: 6.377116725316846e-06\n",
      "Epoch 29 loss: 6.217167463872407e-06\n",
      "Epoch 30 loss: 6.08994174814509e-06\n",
      "\n",
      "\n",
      "Client 4 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.00012369051827117498\n",
      "Epoch 2 loss: 3.0851834125841863e-05\n",
      "Epoch 3 loss: 2.0769616358668863e-05\n",
      "Epoch 4 loss: 1.678048417801144e-05\n",
      "Epoch 5 loss: 1.494649837924599e-05\n",
      "Epoch 6 loss: 1.3734109851820781e-05\n",
      "Epoch 7 loss: 1.274728063159687e-05\n",
      "Epoch 8 loss: 1.1862538674851369e-05\n",
      "Epoch 9 loss: 1.1161772300444122e-05\n",
      "Epoch 10 loss: 1.0557065236113484e-05\n",
      "Epoch 11 loss: 1.0095968651166524e-05\n",
      "Epoch 12 loss: 9.61358774372359e-06\n",
      "Epoch 13 loss: 9.293033361585415e-06\n",
      "Epoch 14 loss: 8.860585591902407e-06\n",
      "Epoch 15 loss: 8.533293806286322e-06\n",
      "Epoch 16 loss: 8.434420368860124e-06\n",
      "Epoch 17 loss: 7.99328344815253e-06\n",
      "Epoch 18 loss: 7.727458616044595e-06\n",
      "Epoch 19 loss: 7.502210305803752e-06\n",
      "Epoch 20 loss: 7.28332902187512e-06\n",
      "Epoch 21 loss: 7.096685372534901e-06\n",
      "Epoch 22 loss: 6.918257628694348e-06\n",
      "Epoch 23 loss: 6.744974957906387e-06\n",
      "Epoch 24 loss: 6.5788300057384805e-06\n",
      "Epoch 25 loss: 6.472517665016919e-06\n",
      "Epoch 26 loss: 6.29735406314077e-06\n",
      "Epoch 27 loss: 6.161418916800575e-06\n",
      "Epoch 28 loss: 6.022833991265263e-06\n",
      "Epoch 29 loss: 5.915821135423795e-06\n",
      "Epoch 30 loss: 5.8212401251931955e-06\n",
      "\n",
      "\n",
      "Client 5 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.0040599877549081\n",
      "Epoch 2 loss: 0.0029234688567617313\n",
      "Epoch 3 loss: 0.0008590741747446075\n",
      "Epoch 4 loss: 0.0002711763211095734\n",
      "Epoch 5 loss: 4.746585164454043e-05\n",
      "Epoch 6 loss: 2.3663761046505967e-05\n",
      "Epoch 7 loss: 2.0579565189423516e-05\n",
      "Epoch 8 loss: 1.8516021515004063e-05\n",
      "Epoch 9 loss: 1.698740420569573e-05\n",
      "Epoch 10 loss: 1.578344875654936e-05\n",
      "Epoch 11 loss: 1.4823370217115926e-05\n",
      "Epoch 12 loss: 1.3981872940129545e-05\n",
      "Epoch 13 loss: 1.3311565237101108e-05\n",
      "Epoch 14 loss: 1.2684487015604363e-05\n",
      "Epoch 15 loss: 1.2148919718667896e-05\n",
      "Epoch 16 loss: 1.1662772790784428e-05\n",
      "Epoch 17 loss: 1.1231386186147326e-05\n",
      "Epoch 18 loss: 1.0829005974384723e-05\n",
      "Epoch 19 loss: 1.0497210087968863e-05\n",
      "Epoch 20 loss: 1.0134247363355271e-05\n",
      "Epoch 21 loss: 9.85243629494689e-06\n",
      "Epoch 22 loss: 9.537240078899793e-06\n",
      "Epoch 23 loss: 9.31158976345323e-06\n",
      "Epoch 24 loss: 9.069024580202969e-06\n",
      "Epoch 25 loss: 8.7948467351807e-06\n",
      "Epoch 26 loss: 8.595398761114094e-06\n",
      "Epoch 27 loss: 8.397361623822907e-06\n",
      "Epoch 28 loss: 8.18270580580643e-06\n",
      "Epoch 29 loss: 7.993279786730892e-06\n",
      "Epoch 30 loss: 7.820956567436953e-06\n",
      "\n",
      "Accuracy of the network: 99.03, Loss: 0.0\n",
      "Loss difference: 0.0\n",
      "Global Round 13 ends\n",
      "\n",
      "\n",
      " ====================== Global Round 15 ======================\n",
      "Client 1 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.003875691003570495\n",
      "Epoch 2 loss: 0.0033986586467707244\n",
      "Epoch 3 loss: 0.0026633306005412424\n",
      "Epoch 4 loss: 0.0010884048229529342\n",
      "Epoch 5 loss: 0.00018869533545723229\n",
      "Epoch 6 loss: 2.0269043849719427e-05\n",
      "Epoch 7 loss: 1.6161248617928016e-05\n",
      "Epoch 8 loss: 1.4485790637481269e-05\n",
      "Epoch 9 loss: 1.2432213685597158e-05\n",
      "Epoch 10 loss: 1.1380312821190305e-05\n",
      "Epoch 11 loss: 1.055259559494271e-05\n",
      "Epoch 12 loss: 9.895362139347778e-06\n",
      "Epoch 13 loss: 9.322794492819785e-06\n",
      "Epoch 14 loss: 8.863203736246757e-06\n",
      "Epoch 15 loss: 8.904310212871825e-06\n",
      "Epoch 16 loss: 8.063392392880833e-06\n",
      "Epoch 17 loss: 7.816010171783952e-06\n",
      "Epoch 18 loss: 7.476355642493347e-06\n",
      "Epoch 19 loss: 7.205614198994936e-06\n",
      "Epoch 20 loss: 6.99065829269445e-06\n",
      "Epoch 21 loss: 6.746013253311714e-06\n",
      "Epoch 22 loss: 6.568539481259251e-06\n",
      "Epoch 23 loss: 6.3661067137961585e-06\n",
      "Epoch 24 loss: 6.202337558664305e-06\n",
      "Epoch 25 loss: 6.110855702901632e-06\n",
      "Epoch 26 loss: 5.8847707332736285e-06\n",
      "Epoch 27 loss: 5.74655723319313e-06\n",
      "Epoch 28 loss: 5.613343622731981e-06\n",
      "Epoch 29 loss: 5.491072192974315e-06\n",
      "Epoch 30 loss: 5.3716086142250885e-06\n",
      "\n",
      "\n",
      "Client 2 dropped\n",
      "Client 3 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.0030584307745828844\n",
      "Epoch 2 loss: 0.0014812471727472915\n",
      "Epoch 3 loss: 0.00016240005731955266\n",
      "Epoch 4 loss: 3.4260865274613096e-05\n",
      "Epoch 5 loss: 2.0816416964091247e-05\n",
      "Epoch 6 loss: 1.7389594981884723e-05\n",
      "Epoch 7 loss: 1.5003190523078832e-05\n",
      "Epoch 8 loss: 1.3540746443540376e-05\n",
      "Epoch 9 loss: 1.284410825937018e-05\n",
      "Epoch 10 loss: 1.1481605341618976e-05\n",
      "Epoch 11 loss: 1.07451154103662e-05\n",
      "Epoch 12 loss: 1.0138601508441126e-05\n",
      "Epoch 13 loss: 9.600463327386184e-06\n",
      "Epoch 14 loss: 9.150207701820604e-06\n",
      "Epoch 15 loss: 8.756357255170317e-06\n",
      "Epoch 16 loss: 8.432988911263458e-06\n",
      "Epoch 17 loss: 8.084530014479514e-06\n",
      "Epoch 18 loss: 7.810855596797251e-06\n",
      "Epoch 19 loss: 7.526300290646974e-06\n",
      "Epoch 20 loss: 7.305212053232542e-06\n",
      "Epoch 21 loss: 7.068663628239977e-06\n",
      "Epoch 22 loss: 6.863821389874535e-06\n",
      "Epoch 23 loss: 6.692610704994481e-06\n",
      "Epoch 24 loss: 6.4983207139124546e-06\n",
      "Epoch 25 loss: 6.331187584438608e-06\n",
      "Epoch 26 loss: 6.179579815443658e-06\n",
      "Epoch 27 loss: 6.033855492089549e-06\n",
      "Epoch 28 loss: 5.911540425367865e-06\n",
      "Epoch 29 loss: 5.77077362100128e-06\n",
      "Epoch 30 loss: 5.6529351653620135e-06\n",
      "\n",
      "\n",
      "Client 4 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.0014803792460149712\n",
      "Epoch 2 loss: 0.00034719132139029817\n",
      "Epoch 3 loss: 3.371184225858449e-05\n",
      "Epoch 4 loss: 2.480894443885128e-05\n",
      "Epoch 5 loss: 2.091863268263244e-05\n",
      "Epoch 6 loss: 1.8368863325560263e-05\n",
      "Epoch 7 loss: 1.682837038740579e-05\n",
      "Epoch 8 loss: 1.5090772947711856e-05\n",
      "Epoch 9 loss: 1.3985198635143841e-05\n",
      "Epoch 10 loss: 1.319310711091765e-05\n",
      "Epoch 11 loss: 1.2445402901596064e-05\n",
      "Epoch 12 loss: 1.162287508226093e-05\n",
      "Epoch 13 loss: 1.1067970032870761e-05\n",
      "Epoch 14 loss: 1.0594335216715792e-05\n",
      "Epoch 15 loss: 1.022721744888786e-05\n",
      "Epoch 16 loss: 9.738885219216167e-06\n",
      "Epoch 17 loss: 9.36909365570692e-06\n",
      "Epoch 18 loss: 9.040407905217045e-06\n",
      "Epoch 19 loss: 8.739860844593524e-06\n",
      "Epoch 20 loss: 8.5483642088753e-06\n",
      "Epoch 21 loss: 8.249825470028391e-06\n",
      "Epoch 22 loss: 7.994510609763039e-06\n",
      "Epoch 23 loss: 7.766976138209929e-06\n",
      "Epoch 24 loss: 7.568593795737517e-06\n",
      "Epoch 25 loss: 7.378070098478996e-06\n",
      "Epoch 26 loss: 7.223849238320383e-06\n",
      "Epoch 27 loss: 7.052484369784533e-06\n",
      "Epoch 28 loss: 6.875499498237257e-06\n",
      "Epoch 29 loss: 6.816950898457407e-06\n",
      "Epoch 30 loss: 6.5855103164225395e-06\n",
      "\n",
      "\n",
      "Client 5 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.0033658679805009376\n",
      "Epoch 2 loss: 0.0017368390175770327\n",
      "Epoch 3 loss: 6.96654672906572e-05\n",
      "Epoch 4 loss: 2.8093606024283077e-05\n",
      "Epoch 5 loss: 2.3224941699517596e-05\n",
      "Epoch 6 loss: 2.0394039263846133e-05\n",
      "Epoch 7 loss: 1.8369543045285802e-05\n",
      "Epoch 8 loss: 1.6737959065424126e-05\n",
      "Epoch 9 loss: 1.5505885670790425e-05\n",
      "Epoch 10 loss: 1.4439662357764632e-05\n",
      "Epoch 11 loss: 1.3762482523677538e-05\n",
      "Epoch 12 loss: 1.2913801707319656e-05\n",
      "Epoch 13 loss: 1.2263246764449246e-05\n",
      "Epoch 14 loss: 1.1671526996477523e-05\n",
      "Epoch 15 loss: 1.123450221633475e-05\n",
      "Epoch 16 loss: 1.0774122065623013e-05\n",
      "Epoch 17 loss: 1.0313891653376994e-05\n",
      "Epoch 18 loss: 1.0071145901838868e-05\n",
      "Epoch 19 loss: 9.61591530361723e-06\n",
      "Epoch 20 loss: 9.311382872010127e-06\n",
      "Epoch 21 loss: 9.022029476542739e-06\n",
      "Epoch 22 loss: 8.81087736514247e-06\n",
      "Epoch 23 loss: 8.498085488310684e-06\n",
      "Epoch 24 loss: 8.25392287502997e-06\n",
      "Epoch 25 loss: 8.055758316226908e-06\n",
      "Epoch 26 loss: 7.835221397641718e-06\n",
      "Epoch 27 loss: 7.660275906524337e-06\n",
      "Epoch 28 loss: 7.455563927241375e-06\n",
      "Epoch 29 loss: 7.3064966575160085e-06\n",
      "Epoch 30 loss: 7.126442317179662e-06\n",
      "\n",
      "Accuracy of the network: 99.14, Loss: 0.0\n",
      "Loss difference: 0.0\n",
      "Global Round 14 ends\n",
      "\n",
      "\n",
      " ====================== Global Round 16 ======================\n",
      "Client 1 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.0012678412708711324\n",
      "Epoch 2 loss: 0.00010482443394218047\n",
      "Epoch 3 loss: 1.785409988205866e-05\n",
      "Epoch 4 loss: 1.430314267599315e-05\n",
      "Epoch 5 loss: 1.22923287224004e-05\n",
      "Epoch 6 loss: 1.1066648290779688e-05\n",
      "Epoch 7 loss: 1.0045129051091224e-05\n",
      "Epoch 8 loss: 9.256346719814247e-06\n",
      "Epoch 9 loss: 8.668267310989628e-06\n",
      "Epoch 10 loss: 8.142616381284064e-06\n",
      "Epoch 11 loss: 7.69684389860614e-06\n",
      "Epoch 12 loss: 7.489685218040704e-06\n",
      "Epoch 13 loss: 7.041287919918587e-06\n",
      "Epoch 14 loss: 6.831918283033824e-06\n",
      "Epoch 15 loss: 6.419327635170001e-06\n",
      "Epoch 16 loss: 6.1854540753673004e-06\n",
      "Epoch 17 loss: 5.9632299649431515e-06\n",
      "Epoch 18 loss: 5.7793974924610145e-06\n",
      "Epoch 19 loss: 5.585795805265689e-06\n",
      "Epoch 20 loss: 5.417886945774386e-06\n",
      "Epoch 21 loss: 5.262678404959835e-06\n",
      "Epoch 22 loss: 5.134055650503728e-06\n",
      "Epoch 23 loss: 5.019549621082412e-06\n",
      "Epoch 24 loss: 4.887176272756548e-06\n",
      "Epoch 25 loss: 4.742718541051969e-06\n",
      "Epoch 26 loss: 4.660329499441037e-06\n",
      "Epoch 27 loss: 4.5278784992709975e-06\n",
      "Epoch 28 loss: 4.426989542424997e-06\n",
      "Epoch 29 loss: 4.508312045140313e-06\n",
      "Epoch 30 loss: 4.242633199988352e-06\n",
      "\n",
      "\n",
      "Client 2 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.00020207831127145104\n",
      "Epoch 2 loss: 1.8020521523702272e-05\n",
      "Epoch 3 loss: 1.4669037485548604e-05\n",
      "Epoch 4 loss: 1.2341925833028084e-05\n",
      "Epoch 5 loss: 1.096804458016825e-05\n",
      "Epoch 6 loss: 9.995861139384618e-06\n",
      "Epoch 7 loss: 9.263231222242197e-06\n",
      "Epoch 8 loss: 8.60424823771419e-06\n",
      "Epoch 9 loss: 8.05992608955372e-06\n",
      "Epoch 10 loss: 7.614732127334876e-06\n",
      "Epoch 11 loss: 7.221738769175785e-06\n",
      "Epoch 12 loss: 6.9196671728371006e-06\n",
      "Epoch 13 loss: 6.580705952782758e-06\n",
      "Epoch 14 loss: 6.312196505969932e-06\n",
      "Epoch 15 loss: 6.0791193348184735e-06\n",
      "Epoch 16 loss: 5.9854962860291345e-06\n",
      "Epoch 17 loss: 5.64997374011337e-06\n",
      "Epoch 18 loss: 5.482512897170868e-06\n",
      "Epoch 19 loss: 5.294657665916657e-06\n",
      "Epoch 20 loss: 5.157672308949961e-06\n",
      "Epoch 21 loss: 5.017262725126711e-06\n",
      "Epoch 22 loss: 4.895624408892827e-06\n",
      "Epoch 23 loss: 4.726520103003624e-06\n",
      "Epoch 24 loss: 4.624068114607689e-06\n",
      "Epoch 25 loss: 4.509993632504349e-06\n",
      "Epoch 26 loss: 4.430975440558416e-06\n",
      "Epoch 27 loss: 4.297761869897581e-06\n",
      "Epoch 28 loss: 4.2235382883252686e-06\n",
      "Epoch 29 loss: 4.120901633133294e-06\n",
      "Epoch 30 loss: 4.0390324367241184e-06\n",
      "\n",
      "\n",
      "Client 3 starts training...\n",
      "losss difference: 0.0\n",
      "last global loss: 0.0\n",
      "Epoch 1 loss: 0.0004559723077752782\n",
      "Epoch 2 loss: 7.568118057309491e-05\n",
      "Epoch 3 loss: 1.5821058962399172e-05\n",
      "Epoch 4 loss: 1.2462325030800465e-05\n",
      "Epoch 5 loss: 1.0871156944255231e-05\n",
      "Epoch 6 loss: 9.705889490284543e-06\n",
      "Epoch 7 loss: 8.884326072226921e-06\n",
      "Epoch 8 loss: 8.263254051884219e-06\n",
      "Epoch 9 loss: 7.75458466288478e-06\n",
      "Epoch 10 loss: 7.350096038790925e-06\n",
      "Epoch 11 loss: 6.932389304562266e-06\n",
      "Epoch 12 loss: 6.614194860642928e-06\n",
      "Epoch 13 loss: 6.320108175895512e-06\n",
      "Epoch 14 loss: 6.093124997561515e-06\n",
      "Epoch 15 loss: 5.857672096644661e-06\n",
      "Epoch 16 loss: 5.651123465423007e-06\n",
      "Epoch 17 loss: 5.452866623593571e-06\n",
      "Epoch 18 loss: 5.289013628900538e-06\n",
      "Epoch 19 loss: 5.131719150031904e-06\n",
      "Epoch 20 loss: 4.998585500801064e-06\n",
      "Epoch 21 loss: 4.960025372448303e-06\n",
      "Epoch 22 loss: 4.721520708320517e-06\n",
      "Epoch 23 loss: 4.605721210367746e-06\n",
      "Epoch 24 loss: 4.486225053948644e-06\n",
      "Epoch 25 loss: 4.408744987553988e-06\n",
      "Epoch 26 loss: 4.2803373929169195e-06\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m algorithm \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFedAvg\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      6\u001B[0m system_heterogeneity\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 7\u001B[0m avg_iid_history \u001B[38;5;241m=\u001B[39m \u001B[43mfederated_learning\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43mmu\u001B[49m\u001B[43m,\u001B[49m\u001B[43msigma\u001B[49m\u001B[43m,\u001B[49m\u001B[43mclient_datasets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtestloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mglobal_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43malgorithm\u001B[49m\u001B[43m,\u001B[49m\u001B[43msystem_heterogeneity\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# Note that FedAvg is a special case of FedProx when mu = 0 and sigma = 1\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[12], line 184\u001B[0m, in \u001B[0;36mfederated_learning\u001B[0;34m(model, mu, sigma, client_datasets, testloader, optimizer, loss_function, global_epochs, local_epochs, algorithm, sys_heter)\u001B[0m\n\u001B[1;32m    181\u001B[0m state_dicts \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m client_id, client_dataloader \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(client_dataloaders):\n\u001B[0;32m--> 184\u001B[0m     client_state_dict \u001B[38;5;241m=\u001B[39m \u001B[43mclient_update\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclient_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43mclient_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43mmu\u001B[49m\u001B[43m,\u001B[49m\u001B[43msigma\u001B[49m\u001B[43m,\u001B[49m\u001B[43mloss_difference\u001B[49m\u001B[43m,\u001B[49m\u001B[43mglobal_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43malgorithm\u001B[49m\u001B[43m,\u001B[49m\u001B[43msys_heter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    185\u001B[0m     state_dicts\u001B[38;5;241m.\u001B[39mappend(client_state_dict)\n\u001B[1;32m    187\u001B[0m global_model \u001B[38;5;241m=\u001B[39m server_aggregate(state_dicts)\n",
      "Cell \u001B[0;32mIn[12], line 123\u001B[0m, in \u001B[0;36mclient_update\u001B[0;34m(received_model, train_data, local_optimizer, loss_f, epoch, client_id, mu, sigma, loss_difference, last_global_loss, algorithm, sys_heter)\u001B[0m\n\u001B[1;32m    121\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m    122\u001B[0m     local_optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m--> 123\u001B[0m     running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mabs\u001B[39m(running_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_data) \u001B[38;5;241m-\u001B[39m last_global_loss) \u001B[38;5;241m<\u001B[39m sigma\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mabs\u001B[39m(loss_difference) \u001B[38;5;129;01mand\u001B[39;00m algorithm \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFedProx\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;66;03m# allow good enough results for all clients\u001B[39;00m\n\u001B[1;32m    126\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClient \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclient_id\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m stops training at epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m because good enough results hve been obtained at Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrunning_loss\u001B[38;5;250m \u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mlen\u001B[39m(train_data)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Federated Average without system and statistical heterogeneity\n",
    "client_datasets=create_iid_partitions(trainset, number_of_clients)\n",
    "mu=0\n",
    "sigma=0\n",
    "algorithm = \"FedAvg\"\n",
    "system_heterogeneity=0\n",
    "avg_iid_history = federated_learning(model,mu,sigma,client_datasets, testloader,optimizer, loss_function, global_epochs, local_epochs,algorithm,system_heterogeneity) # Note that FedAvg is a special case of FedProx when mu = 0 and sigma = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T21:40:39.030554683Z",
     "start_time": "2024-03-16T21:26:16.672413972Z"
    }
   },
   "id": "5ea209cd2903e912"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Under System and Statistical Heterogeneity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67c6a7d9848613e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "statistical_heterogeneity=10\n",
    "system_heterogeneity=9\n",
    "client_datasets=create_non_iid_partitions(trainset, number_of_clients,statistical_heterogeneity)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Federated Proximal with system and statistical heterogeneity\n",
    "mu = 0.1\n",
    "sigma = 0.5\n",
    "algorithm = \"FedProx\"\n",
    "prox_niid_history=federated_learning(model,mu,sigma,client_datasets, testloader,optimizer, loss_function, global_epochs, local_epochs,algorithm,system_heterogeneity)\n",
    "\n",
    "# Federated Proximal with system and statistical heterogeneity\n",
    "algorithm = \"FedAvg\"\n",
    "mu = 0 \n",
    "sigma = 1\n",
    "avg_niid_history=federated_learning(model,mu,sigma,client_datasets, testloader,optimizer, loss_function, global_epochs, local_epochs,algorithm,system_heterogeneity)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T21:40:39.033296643Z",
     "start_time": "2024-03-16T21:40:39.031427068Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# plotting the results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71f186ff7c6bd7bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # pip install matplotlib\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# No heterogeneity\n",
    "fedAvg_iid_acc = [avg_iid_history[i][0] for i in range(global_epochs)]\n",
    "\n",
    "fedProx_niid_acc = [prox_niid_history[i][0] for i in range(global_epochs)]\n",
    "\n",
    "fedAvg_niid_acc = [avg_niid_history[i][0] for i in range(global_epochs)]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-16T21:40:39.031961959Z"
    }
   },
   "id": "4000fe9b1b89df9a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# No heterogeneity results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df3886eeb9b8ce02"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_iter = 22\n",
    "plt.figure(figsize=(15, 7),facecolor='white')\n",
    "plt.title('FedAvg Accuracy on CIFAR-10 without heterogeneity',fontsize=25,color='black')\n",
    "plt.plot(fedAvg_iid_acc, label='Fed_avg', color=\"black\", linestyle=\"dashed\", linewidth=4)\n",
    "plt.xticks(np.arange(0, n_iter, 2),fontsize=25,color='black')\n",
    "plt.yticks(fontsize=20,color='black')\n",
    "ax = plt.gca()\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.set_facecolor('white')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-16T21:40:39.032808301Z"
    }
   },
   "id": "6c81a9ce1a8e89ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# With heterogeneity results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a07448c834db68a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7),facecolor='white')\n",
    "plt.title('FedProx Accuracy on CIFAR-10 with heterogeneity',fontsize=25,color='black')\n",
    "plt.plot(fedProx_niid_acc, label='Fed_prox', color=\"red\", linestyle=\"solid\", linewidth=4)\n",
    "plt.plot(fedAvg_niid_acc, label='Fed_avg', color=\"black\", linestyle=\"dashed\", linewidth=4)\n",
    "plt.xticks(np.arange(0, n_iter, 2),fontsize=25,color='black')\n",
    "plt.yticks(fontsize=20,color='black')\n",
    "ax = plt.gca()\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.set_facecolor('white')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T21:40:39.033935242Z",
     "start_time": "2024-03-16T21:40:39.033821691Z"
    }
   },
   "id": "97bb3b36c7b76c77"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d494388dbbf27335"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
